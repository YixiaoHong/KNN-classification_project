{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Lab_1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"TBvzhAlwoJFp","colab_type":"text"},"source":["# APS1070\n","#### Basic Principles and Models - Project 1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hJqa8JCbsXAR","colab_type":"text"},"source":["Project 1 has two parts: a tutorial component (which will be covered in labs) and an exercises component (to be completed as homework, individually). Overall, this project is worth 12.5% of your final grade. Completing the tutorial section is worth 2.5 marks. The exercises section will be graded out of the remaining 10 marks."]},{"cell_type":"markdown","metadata":{"id":"AC7fb3NUoJFq","colab_type":"text"},"source":["In this first lab, we will be using the popular machine learning library [scikit-learn](https://scikit-learn.org/stable/) in tandem with a popular scientific computing library in Python, [NumPy](https://www.numpy.org/), to investigate basic machine learning principles and models. The topics that will be covered in this lab include:\n","* Introduction to scikit-learn and NumPy\n","* Data preparation and cleaning with Pandas\n","* Exploratory data analysis (EDA)\n","* Nearest neighbors classification algorithm\n","\n","*Note:* Some other useful Python libraries include [matplotlib](https://matplotlib.org/) (for plotting/graphing) and [Pandas](https://pandas.pydata.org/) (for data analysis), though we won't be going into detail on these in this bootcamp. \n","\n","##### Jupyter Notebooks\n","This lab will be using [Jupyter Notebooks](https://jupyter.org/) as a Python development environment. Hopefully you're somewhat familiar with them. Write your code in *cells* (this is a cell!) and execute your code by pressing the *play* button (up top) or by entering *ctrl+enter*. To format a cell for text, you can select \"Markdown\" from the dropdown - the default formatting is \"Code\", which will usually be what you want.\n","\n","#### Getting started\n","Let's get started. First, we're going to test that we're able to import the required libraries.  \n","**>> Run the code in the next cell** to import scikit-learn and NumPy."]},{"cell_type":"code","metadata":{"id":"02vFf7HBoJFq","colab_type":"code","colab":{}},"source":["import numpy as np\n","import sklearn "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bXYj_1fHoJFs","colab_type":"text"},"source":["### NumPy Basics\n","\n","Great. Let's move on to our next topic: getting a handle on NumPy basics. You can think of NumPy as sort of like a MATLAB for Python (if that helps). The main object is multidimensional arrays, and these come in particularly handy when working with data and machine learning algorithms.\n","\n","Let's create a 2x4 array containing the numbers 1 through 8 and conduct some basic operations on it.  \n","**>> Run the code in the next cell to create and print the array.***"]},{"cell_type":"code","metadata":{"id":"xs3V4laeoJFt","colab_type":"code","outputId":"e6b2b013-4728-4cdc-f309-b7cfaa7c7180","executionInfo":{"status":"ok","timestamp":1572099819996,"user_tz":240,"elapsed":1161,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["array = np.arange(8).reshape(-1,4)\n","array"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1, 2, 3],\n","       [4, 5, 6, 7]])"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"xICCkhfNoJFu","colab_type":"text"},"source":["We can access the shape, number of dimensions, data type, and number of elements in our array as follows:  \n","*(Tip: use \"print()\" when you want a cell to output more than one thing, or you want to append text to your output, otherwise the cell will output the last object you call, as in the cell above)*"]},{"cell_type":"code","metadata":{"id":"ncoFbUrloJFv","colab_type":"code","outputId":"6d5625d4-eb28-40fe-e227-719dcecfc922","executionInfo":{"status":"ok","timestamp":1572099819997,"user_tz":240,"elapsed":1152,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print (\"Shape:\", array.shape)\n","print (\"Dimensions:\", array.ndim)\n","print (\"Data type:\" , array.dtype.name)\n","print (\"Number of elements:\", array.size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Shape: (2, 4)\n","Dimensions: 2\n","Data type: int64\n","Number of elements: 8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"paM6nuswSMYP"},"source":["If we have a Python list containing a set of numbers, we can use it to create an array:  \n","*(Tip: if you click on a function call, such as array(), and press \"shift+tab\" the Notebook will provide you all the details of the function)*"]},{"cell_type":"code","metadata":{"id":"YBuAwh7ZoJFw","colab_type":"code","outputId":"254d45b4-1f2b-4a07-c84d-8c42c7c1f3d8","executionInfo":{"status":"ok","timestamp":1572099819998,"user_tz":240,"elapsed":1142,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["mylist = [0, 1, 1, 2, 3, 5, 8, 13, 21]\n","myarray = np.array(mylist)\n","myarray"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  1,  2,  3,  5,  8, 13, 21])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HmkO38ZxSMQ-"},"source":["And we can do it for nested lists as well, creating multidimensional NumPy arrays:"]},{"cell_type":"code","metadata":{"id":"phcNKMipoJFy","colab_type":"code","outputId":"4c6611e6-782e-4eb8-8c0f-419a68481b4f","executionInfo":{"status":"ok","timestamp":1572099819999,"user_tz":240,"elapsed":1132,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["my2dlist = [[1,2,3],[4,5,6]]\n","my2darray = np.array(my2dlist)\n","my2darray"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2, 3],\n","       [4, 5, 6]])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"eg4tCbtDoJF0","colab_type":"text"},"source":["We can also index and slice NumPy arrays like we would do with a Python list or another container object as follows:"]},{"cell_type":"code","metadata":{"id":"5Lud5Oz6oJF0","colab_type":"code","outputId":"7e9b7141-e040-4e61-8f26-337b4e0a175a","executionInfo":{"status":"ok","timestamp":1572099820000,"user_tz":240,"elapsed":1122,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["array = np.arange(10)\n","print (\"Originally: \", array)\n","print (\"First four elements: \", array[:4])\n","print (\"After the first four elements: \", array[4:])\n","print (\"The last element: \", array[-1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Originally:  [0 1 2 3 4 5 6 7 8 9]\n","First four elements:  [0 1 2 3]\n","After the first four elements:  [4 5 6 7 8 9]\n","The last element:  9\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jk9CDc_moJF2","colab_type":"text"},"source":["And we can index/slice multidimensional arrays, too."]},{"cell_type":"code","metadata":{"id":"L4gkgltBoJF2","colab_type":"code","outputId":"00798b95-78b9-4cdb-cd39-d77d8f2bcb44","executionInfo":{"status":"ok","timestamp":1572099820001,"user_tz":240,"elapsed":1112,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["array = np.array([[1,2,3],[4,5,6]])\n","print (\"Originally: \", array)\n","print (\"First row only: \", array[0])\n","print (\"First column only: \", array[:,0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Originally:  [[1 2 3]\n"," [4 5 6]]\n","First row only:  [1 2 3]\n","First column only:  [1 4]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4kimFdIJoJF5","colab_type":"text"},"source":["#### Sneak preview\n","\n","Often, when designing a machine learning classifier, it can be useful to compare an array of predictions (0 or 1 values) to another array of true values. We can do this pretty easily in NumPy to compute the *accuracy* (e.g., the number of values that are the same), for example, as follows:"]},{"cell_type":"code","metadata":{"id":"UrVyjSiYoJF6","colab_type":"code","outputId":"9e36180d-42e3-4a09-dbda-7bbf47bfb96e","executionInfo":{"status":"ok","timestamp":1572099820002,"user_tz":240,"elapsed":1101,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["true_values = [0, 0, 1, 1, 1, 1, 1, 0, 1, 0]\n","predictions = [0, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n","\n","true_values_array = np.array(true_values)\n","predictions_array = np.array(predictions)\n","\n","accuracy = np.sum(true_values_array == predictions_array) / true_values_array.size\n","print (\"Accuracy: \", accuracy * 100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy:  70.0 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NTrKw3aEoJF7","colab_type":"text"},"source":["In the previous cell, we took two Python lists, converted them to NumPy arrays, and then used a combination of np.sum() and .size to compute the accuracy (proportion of elements that are pairwise equal). A tiny bit more advanced, but demonstrates the power of NumPy arrays.\n","\n","You'll notice we didn't used nested loops to conduct the comparison, but instead used the np.sum() function. This is an example of a vectorized operation within NumPy that is much more efficient when dealing with large datasets."]},{"cell_type":"markdown","metadata":{"id":"DZzw94WdoJF8","colab_type":"text"},"source":["### Pandas basics\n","\n","Pandas is an incredibly useful library that allows us to work with large datasets in Python. It contains myriad useful tools, and is highly compatible with other libraries like Scikit-learn, so you don't have to spend any time getting the two to play nicely together.\n","\n","First we are going to load a dataset with Pandas:"]},{"cell_type":"code","metadata":{"id":"Z8Nr62k7oJF8","colab_type":"code","outputId":"e497e73d-3a7b-446d-d6a2-b23bca567b8a","executionInfo":{"status":"ok","timestamp":1572099825748,"user_tz":240,"elapsed":6834,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["!pip install wget"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=93b1435d0f8f427989d1da403f61e012a21543013f159fa2dd28e220377512b8\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TFs45of3oJF9","colab_type":"code","outputId":"db51a16a-57ab-46d9-f920-59fcb54a4a5a","executionInfo":{"status":"ok","timestamp":1572099829875,"user_tz":240,"elapsed":10952,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import wget\n","\n","wget.download(\n","    'https://github.com/alexwolson/APS1070_data/raw/master/arabica_data.csv',\n","    'arabica_data.csv'\n",")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'arabica_data.csv'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"PrgXCIXeoJF_","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","df = pd.read_csv('arabica_data.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNyU-L7hoJGA","colab_type":"text"},"source":["With Pandas, the main object we work with is referred to as a _DataFrame_ (hence calling our object here df). A DataFrame stores our dataset in a way that immediately gives us a lot of power to interact with it. If you just put the DataFrame in a cell on its own, you instantly get a clear, easy to read preview of the data you have:"]},{"cell_type":"code","metadata":{"id":"mwyULfgooJGB","colab_type":"code","outputId":"348b8652-89c4-497b-aad1-d46374f60614","executionInfo":{"status":"ok","timestamp":1572099829879,"user_tz":240,"elapsed":10943,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Bag Weight</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Color</th>\n","      <th>Company</th>\n","      <th>Country of Origin</th>\n","      <th>Cupper Points</th>\n","      <th>Expiration</th>\n","      <th>Farm Name</th>\n","      <th>Flavor</th>\n","      <th>Grading Date</th>\n","      <th>Harvest Year</th>\n","      <th>ICO Number</th>\n","      <th>In-Country Partner</th>\n","      <th>Mill</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Processing Method</th>\n","      <th>Producer</th>\n","      <th>Region</th>\n","      <th>Species</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>Variety</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>8.75</td>\n","      <td>8.67</td>\n","      <td>8.67</td>\n","      <td>60 kg</td>\n","      <td>8.42</td>\n","      <td>8.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>metad agricultural developmet plc</td>\n","      <td>Ethiopia</td>\n","      <td>8.75</td>\n","      <td>April 3rd, 2016</td>\n","      <td>METAD PLC</td>\n","      <td>8.83</td>\n","      <td>April 4th, 2015</td>\n","      <td>2014</td>\n","      <td>2014/2015</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>metad plc</td>\n","      <td>0.12</td>\n","      <td>300</td>\n","      <td>Washed / Wet</td>\n","      <td>METAD PLC</td>\n","      <td>guji-hambela</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>NaN</td>\n","      <td>2200.00</td>\n","      <td>1950.00</td>\n","      <td>2075.00</td>\n","      <td>90.58</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>8.58</td>\n","      <td>8.50</td>\n","      <td>8.75</td>\n","      <td>60 kg</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>metad agricultural developmet plc</td>\n","      <td>Ethiopia</td>\n","      <td>8.58</td>\n","      <td>April 3rd, 2016</td>\n","      <td>METAD PLC</td>\n","      <td>8.67</td>\n","      <td>April 4th, 2015</td>\n","      <td>2014</td>\n","      <td>2014/2015</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>metad plc</td>\n","      <td>0.12</td>\n","      <td>300</td>\n","      <td>Washed / Wet</td>\n","      <td>METAD PLC</td>\n","      <td>guji-hambela</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Other</td>\n","      <td>2200.00</td>\n","      <td>1950.00</td>\n","      <td>2075.00</td>\n","      <td>89.92</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>1</td>\n","      <td>8.42</td>\n","      <td>8.33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Guatemala</td>\n","      <td>9.25</td>\n","      <td>May 31st, 2011</td>\n","      <td>San Marcos Barrancas \"San Cristobal Cuch</td>\n","      <td>8.50</td>\n","      <td>May 31st, 2010</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>NaN</td>\n","      <td>0.00</td>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1800.00</td>\n","      <td>1600.00</td>\n","      <td>1700.00</td>\n","      <td>89.75</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>8.42</td>\n","      <td>8.42</td>\n","      <td>8.17</td>\n","      <td>60 kg</td>\n","      <td>8.25</td>\n","      <td>8.50</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>yidnekachew debessa coffee plantation</td>\n","      <td>Ethiopia</td>\n","      <td>8.67</td>\n","      <td>March 25th, 2016</td>\n","      <td>Yidnekachew Dabessa Coffee Plantation</td>\n","      <td>8.58</td>\n","      <td>March 26th, 2015</td>\n","      <td>2014</td>\n","      <td>NaN</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>wolensu</td>\n","      <td>0.11</td>\n","      <td>320</td>\n","      <td>Natural / Dry</td>\n","      <td>Yidnekachew Dabessa Coffee Plantation</td>\n","      <td>oromia</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>NaN</td>\n","      <td>2200.00</td>\n","      <td>1800.00</td>\n","      <td>2000.00</td>\n","      <td>89.00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>8.50</td>\n","      <td>8.25</td>\n","      <td>8.25</td>\n","      <td>60 kg</td>\n","      <td>8.33</td>\n","      <td>8.42</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>metad agricultural developmet plc</td>\n","      <td>Ethiopia</td>\n","      <td>8.58</td>\n","      <td>April 3rd, 2016</td>\n","      <td>METAD PLC</td>\n","      <td>8.50</td>\n","      <td>April 4th, 2015</td>\n","      <td>2014</td>\n","      <td>2014/2015</td>\n","      <td>METAD Agricultural Development plc</td>\n","      <td>metad plc</td>\n","      <td>0.12</td>\n","      <td>300</td>\n","      <td>Washed / Wet</td>\n","      <td>METAD PLC</td>\n","      <td>guji-hambela</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Other</td>\n","      <td>2200.00</td>\n","      <td>1950.00</td>\n","      <td>2075.00</td>\n","      <td>88.83</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1306</th>\n","      <td>1306</td>\n","      <td>6.50</td>\n","      <td>6.17</td>\n","      <td>7.00</td>\n","      <td>1 kg</td>\n","      <td>6.17</td>\n","      <td>6.67</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>Green</td>\n","      <td>cadexsa</td>\n","      <td>Mexico</td>\n","      <td>6.75</td>\n","      <td>May 15th, 2015</td>\n","      <td>EL CENTENARIO</td>\n","      <td>6.33</td>\n","      <td>September 17th, 2012</td>\n","      <td>2012</td>\n","      <td>1104328663</td>\n","      <td>AMECAFE</td>\n","      <td>cadexsa</td>\n","      <td>0.10</td>\n","      <td>12</td>\n","      <td>Washed / Wet</td>\n","      <td>Omar Acosta</td>\n","      <td>marcala</td>\n","      <td>Arabica</td>\n","      <td>8.00</td>\n","      <td>8.00</td>\n","      <td>Catuai</td>\n","      <td>1450.00</td>\n","      <td>1450.00</td>\n","      <td>1450.00</td>\n","      <td>68.33</td>\n","    </tr>\n","    <tr>\n","      <th>1307</th>\n","      <td>1307</td>\n","      <td>7.42</td>\n","      <td>6.25</td>\n","      <td>7.08</td>\n","      <td>2 kg</td>\n","      <td>6.75</td>\n","      <td>7.25</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>6.00</td>\n","      <td>None</td>\n","      <td>terra mia</td>\n","      <td>Haiti</td>\n","      <td>6.42</td>\n","      <td>September 17th, 2013</td>\n","      <td>200 farms</td>\n","      <td>6.83</td>\n","      <td>May 24th, 2012</td>\n","      <td>2012</td>\n","      <td>NaN</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>la esperanza, municipio juchique de ferrer, ve...</td>\n","      <td>0.11</td>\n","      <td>1</td>\n","      <td>Natural / Dry</td>\n","      <td>JUAN CARLOS GARCÍA LOPEZ</td>\n","      <td>juchique de ferrer</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>67.92</td>\n","    </tr>\n","    <tr>\n","      <th>1308</th>\n","      <td>1308</td>\n","      <td>6.67</td>\n","      <td>6.42</td>\n","      <td>6.75</td>\n","      <td>69 kg</td>\n","      <td>6.67</td>\n","      <td>7.08</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>6.00</td>\n","      <td>Blue-Green</td>\n","      <td>haiti coffee</td>\n","      <td>Nicaragua</td>\n","      <td>6.17</td>\n","      <td>May 24th, 2013</td>\n","      <td>Finca Las Marías</td>\n","      <td>6.58</td>\n","      <td>June 6th, 2017</td>\n","      <td>2016</td>\n","      <td>017-053-0211/ 017-053-0212</td>\n","      <td>Instituto Hondureño del Café</td>\n","      <td>coeb koperativ ekselsyo basen (350 members)</td>\n","      <td>0.14</td>\n","      <td>550</td>\n","      <td>Other</td>\n","      <td>COEB Koperativ Ekselsyo Basen</td>\n","      <td>department d'artibonite , haiti</td>\n","      <td>Arabica</td>\n","      <td>6.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>63.08</td>\n","    </tr>\n","    <tr>\n","      <th>1309</th>\n","      <td>1309</td>\n","      <td>6.25</td>\n","      <td>6.33</td>\n","      <td>7.25</td>\n","      <td>1 kg</td>\n","      <td>6.08</td>\n","      <td>6.42</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1.33</td>\n","      <td>Green</td>\n","      <td>exportadora atlantic s.a</td>\n","      <td>Guatemala</td>\n","      <td>6.67</td>\n","      <td>June 6th, 2018</td>\n","      <td>FINCA EL LIMON</td>\n","      <td>6.58</td>\n","      <td>May 24th, 2012</td>\n","      <td>2012</td>\n","      <td>11/853/165</td>\n","      <td>Asociacion Nacional Del Café</td>\n","      <td>beneficio atlantic condega</td>\n","      <td>0.13</td>\n","      <td>275</td>\n","      <td>Washed / Wet</td>\n","      <td>Teófilo Narváez</td>\n","      <td>jalapa</td>\n","      <td>Arabica</td>\n","      <td>6.00</td>\n","      <td>6.00</td>\n","      <td>Caturra</td>\n","      <td>1100.00</td>\n","      <td>1100.00</td>\n","      <td>1100.00</td>\n","      <td>59.83</td>\n","    </tr>\n","    <tr>\n","      <th>1310</th>\n","      <td>1310</td>\n","      <td>7.67</td>\n","      <td>6.67</td>\n","      <td>7.50</td>\n","      <td>0 lbs</td>\n","      <td>6.67</td>\n","      <td>7.33</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.00</td>\n","      <td>Green</td>\n","      <td>unicafe</td>\n","      <td>Ethiopia</td>\n","      <td>6.00</td>\n","      <td>May 24th, 2013</td>\n","      <td>TEST</td>\n","      <td>6.67</td>\n","      <td>June 18th, 2010</td>\n","      <td>TEST</td>\n","      <td>TEST</td>\n","      <td>Ethiopia Commodity Exchange</td>\n","      <td>beneficio serben</td>\n","      <td>0.10</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>WILLIAM ESTUARDO MARTINEZ PACHECO</td>\n","      <td>nuevo oriente</td>\n","      <td>Arabica</td>\n","      <td>1.33</td>\n","      <td>8.00</td>\n","      <td>Catuai</td>\n","      <td>1417.32</td>\n","      <td>1417.32</td>\n","      <td>1417.32</td>\n","      <td>43.13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1311 rows × 35 columns</p>\n","</div>"],"text/plain":["      Unnamed: 0  Acidity  ...  altitude_mean_meters  quality_score\n","0              0     8.75  ...               2075.00          90.58\n","1              1     8.58  ...               2075.00          89.92\n","2              2     8.42  ...               1700.00          89.75\n","3              3     8.42  ...               2000.00          89.00\n","4              4     8.50  ...               2075.00          88.83\n","...          ...      ...  ...                   ...            ...\n","1306        1306     6.50  ...               1450.00          68.33\n","1307        1307     7.42  ...                900.00          67.92\n","1308        1308     6.67  ...                350.00          63.08\n","1309        1309     6.25  ...               1100.00          59.83\n","1310        1310     7.67  ...               1417.32          43.13\n","\n","[1311 rows x 35 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"SRMk05QJoJGC","colab_type":"text"},"source":["But even though this is printed out well, the dataset is a bit too large for this view to be anything but overwhelming. Luckily, Pandas allows us to easily get some summary statistics about our data."]},{"cell_type":"code","metadata":{"id":"IdcIgH0roJGD","colab_type":"code","outputId":"9194b3a4-1412-4aeb-c8f1-9cea14aad906","executionInfo":{"status":"ok","timestamp":1572099830268,"user_tz":240,"elapsed":11324,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":334}},"source":["df.describe()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Cupper Points</th>\n","      <th>Flavor</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.00000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1311.000000</td>\n","      <td>1084.000000</td>\n","      <td>1084.000000</td>\n","      <td>1084.000000</td>\n","      <td>1311.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>655.000000</td>\n","      <td>7.538764</td>\n","      <td>7.403158</td>\n","      <td>7.569527</td>\n","      <td>7.523288</td>\n","      <td>7.523387</td>\n","      <td>0.450038</td>\n","      <td>3.626240</td>\n","      <td>9.83312</td>\n","      <td>7.502441</td>\n","      <td>7.523539</td>\n","      <td>0.088963</td>\n","      <td>153.678108</td>\n","      <td>9.910900</td>\n","      <td>9.839497</td>\n","      <td>1808.751552</td>\n","      <td>1759.456703</td>\n","      <td>1784.104128</td>\n","      <td>82.148825</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>378.597412</td>\n","      <td>0.319773</td>\n","      <td>0.349945</td>\n","      <td>0.315930</td>\n","      <td>0.349174</td>\n","      <td>0.293089</td>\n","      <td>2.017571</td>\n","      <td>5.482857</td>\n","      <td>0.77135</td>\n","      <td>0.428989</td>\n","      <td>0.341817</td>\n","      <td>0.047907</td>\n","      <td>129.760079</td>\n","      <td>0.454824</td>\n","      <td>0.491508</td>\n","      <td>8767.192330</td>\n","      <td>8767.851565</td>\n","      <td>8767.021485</td>\n","      <td>2.893505</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>5.250000</td>\n","      <td>6.170000</td>\n","      <td>5.080000</td>\n","      <td>6.080000</td>\n","      <td>5.250000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>5.170000</td>\n","      <td>6.080000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.330000</td>\n","      <td>6.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>43.130000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>327.500000</td>\n","      <td>7.330000</td>\n","      <td>7.250000</td>\n","      <td>7.420000</td>\n","      <td>7.330000</td>\n","      <td>7.330000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>10.00000</td>\n","      <td>7.250000</td>\n","      <td>7.330000</td>\n","      <td>0.090000</td>\n","      <td>14.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>1100.000000</td>\n","      <td>1100.000000</td>\n","      <td>1100.000000</td>\n","      <td>81.170000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>655.000000</td>\n","      <td>7.500000</td>\n","      <td>7.420000</td>\n","      <td>7.580000</td>\n","      <td>7.500000</td>\n","      <td>7.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>10.00000</td>\n","      <td>7.500000</td>\n","      <td>7.580000</td>\n","      <td>0.110000</td>\n","      <td>170.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>1350.000000</td>\n","      <td>1310.640000</td>\n","      <td>1310.640000</td>\n","      <td>82.500000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>982.500000</td>\n","      <td>7.750000</td>\n","      <td>7.580000</td>\n","      <td>7.750000</td>\n","      <td>7.750000</td>\n","      <td>7.670000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>10.00000</td>\n","      <td>7.750000</td>\n","      <td>7.750000</td>\n","      <td>0.120000</td>\n","      <td>275.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>1650.000000</td>\n","      <td>1600.000000</td>\n","      <td>1600.000000</td>\n","      <td>83.670000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1310.000000</td>\n","      <td>8.750000</td>\n","      <td>8.670000</td>\n","      <td>8.750000</td>\n","      <td>8.750000</td>\n","      <td>8.580000</td>\n","      <td>31.000000</td>\n","      <td>55.000000</td>\n","      <td>10.00000</td>\n","      <td>10.000000</td>\n","      <td>8.830000</td>\n","      <td>0.280000</td>\n","      <td>1062.000000</td>\n","      <td>10.000000</td>\n","      <td>10.000000</td>\n","      <td>190164.000000</td>\n","      <td>190164.000000</td>\n","      <td>190164.000000</td>\n","      <td>90.580000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Unnamed: 0      Acidity  ...  altitude_mean_meters  quality_score\n","count  1311.000000  1311.000000  ...           1084.000000    1311.000000\n","mean    655.000000     7.538764  ...           1784.104128      82.148825\n","std     378.597412     0.319773  ...           8767.021485       2.893505\n","min       0.000000     5.250000  ...              1.000000      43.130000\n","25%     327.500000     7.330000  ...           1100.000000      81.170000\n","50%     655.000000     7.500000  ...           1310.640000      82.500000\n","75%     982.500000     7.750000  ...           1600.000000      83.670000\n","max    1310.000000     8.750000  ...         190164.000000      90.580000\n","\n","[8 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Eu_NKdsUoJGE","colab_type":"text"},"source":["Let's say we want to zero in on a single column. This is done the same way that you access a dictionary entry:"]},{"cell_type":"code","metadata":{"id":"5AfhzRXIoJGE","colab_type":"code","outputId":"12464179-ace3-4532-9aab-cad6d935b13e","executionInfo":{"status":"ok","timestamp":1572099830269,"user_tz":240,"elapsed":11319,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["df['Species']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       Arabica\n","1       Arabica\n","2       Arabica\n","3       Arabica\n","4       Arabica\n","         ...   \n","1306    Arabica\n","1307    Arabica\n","1308    Arabica\n","1309    Arabica\n","1310    Arabica\n","Name: Species, Length: 1311, dtype: object"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"PL32j4QcoJGF","colab_type":"text"},"source":["Using this method of column access on its own returns a `series` object - think of this as a DataFrame with only one column. If you want to get the raw values however, you can simply specify this by adding `.values` after your entry. Using this, and by putting the object in a `Set` (which does not allow duplicate entries), we can quickly see all of the possible values for any column:"]},{"cell_type":"code","metadata":{"id":"ZQLTkn5LoJGG","colab_type":"code","outputId":"ac81e6d3-a62e-41d2-d565-93992c107eb4","executionInfo":{"status":"ok","timestamp":1572099830270,"user_tz":240,"elapsed":11313,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["set(df['Variety'].values)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Arusha',\n"," 'Blue Mountain',\n"," 'Bourbon',\n"," 'Catimor',\n"," 'Catuai',\n"," 'Caturra',\n"," 'Ethiopian Heirlooms',\n"," 'Ethiopian Yirgacheffe',\n"," 'Gesha',\n"," 'Hawaiian Kona',\n"," 'Java',\n"," 'Mandheling',\n"," 'Marigojipe',\n"," 'Moka Peaberry',\n"," 'Mundo Novo',\n"," 'Other',\n"," 'Pacamara',\n"," 'Pacas',\n"," 'Pache Comun',\n"," 'Peaberry',\n"," 'Ruiru 11',\n"," 'SL14',\n"," 'SL28',\n"," 'SL34',\n"," 'Sulawesi',\n"," 'Sumatra',\n"," 'Sumatra Lintong',\n"," 'Typica',\n"," 'Yellow Bourbon',\n"," nan}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"6fJoOBgjoJGI","colab_type":"text"},"source":["You may notice that the final entry in this set isn't like the others - it's `nan`, which in Pandas denotes a missing entry. When working with real world datasets it's very common for entries to be missing, and there are a variety of ways of approaching a problem like this. For now, though, we are simply going to tell Pandas to drop any row that has a missing column, using the `dropna()` method."]},{"cell_type":"code","metadata":{"id":"Vy3se4KxoJGI","colab_type":"code","colab":{}},"source":["df_clean = df.dropna()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JdkOZCJloJGK","colab_type":"text"},"source":["**YOUR TURN** How many entries did we lose by dropping all `nan`s?  770\n","\n","* What percentage of entries are left in `df_clean`? __41.27%__\n","* What column had the highest number of `nan` entries? (This can be done in one line - use Google!) __'Farm Name'_"]},{"cell_type":"code","metadata":{"id":"1HaVQYqjoJGK","colab_type":"code","outputId":"d81bfa5d-b9c2-4478-819f-380ef7ff5323","executionInfo":{"status":"ok","timestamp":1572099830271,"user_tz":240,"elapsed":11306,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["### Your code here\n","rowDiff = len(df) - len(df_clean)\n","\n","print(\"There are \", rowDiff, \" entries lost by dropping all nans.\") \n","\n","percent = len(df_clean)/len(df) *100\n","\n","print(\"%.2f\" % round(percent,2), \"% of entries are left in df_clean. \") \n","\n","maxValue = df.isnull().sum().idxmax()\n","\n","print(\"Column '\", maxValue, \"' has the highest number of nan entries which is\", df.isnull().sum()[maxValue], \". \")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["There are  770  entries lost by dropping all nans.\n","41.27 % of entries are left in df_clean. \n","Column ' Farm Name ' has the highest number of nan entries which is 356 . \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_1p4DU9poJGN","colab_type":"text"},"source":["As you perform this analysis, you will probably notice that we've lost _quite a bit_ of our original data by simply dropping the `nan` values. There is another approach that we can examine, however. Instead of dropping the missing entries entirely, we can _impute_ their value using the data we do have. For a single column we can do this like so:"]},{"cell_type":"code","metadata":{"id":"9F6N5-_uoJGN","colab_type":"code","colab":{}},"source":["from sklearn.impute import SimpleImputer\n","\n","imp = SimpleImputer(\n","    missing_values=np.nan,\n","    strategy='mean',\n","    verbose=1\n",")\n","\n","imp.fit(\n","    df['altitude_mean_meters'].values.reshape((-1,1)) #we have to do the reshape operation because we are only using one feature.\n",")\n","\n","\n","df['altitude_mean_meters_imputed'] = imp.transform(df['altitude_mean_meters'].values.reshape((-1,1)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mfp3D574oJGP","colab_type":"code","outputId":"7b54fd75-2f9e-4d13-9c1e-1346396a165e","executionInfo":{"status":"ok","timestamp":1572099830273,"user_tz":240,"elapsed":11299,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":359}},"source":["df[['altitude_mean_meters','altitude_mean_meters_imputed']].head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>altitude_mean_meters</th>\n","      <th>altitude_mean_meters_imputed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2075.0</td>\n","      <td>2075.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2075.0</td>\n","      <td>2075.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1700.0</td>\n","      <td>1700.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2000.0</td>\n","      <td>2000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2075.0</td>\n","      <td>2075.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>NaN</td>\n","      <td>1784.104128</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>1784.104128</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1635.0</td>\n","      <td>1635.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1635.0</td>\n","      <td>1635.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1822.5</td>\n","      <td>1822.500000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   altitude_mean_meters  altitude_mean_meters_imputed\n","0                2075.0                   2075.000000\n","1                2075.0                   2075.000000\n","2                1700.0                   1700.000000\n","3                2000.0                   2000.000000\n","4                2075.0                   2075.000000\n","5                   NaN                   1784.104128\n","6                   NaN                   1784.104128\n","7                1635.0                   1635.000000\n","8                1635.0                   1635.000000\n","9                1822.5                   1822.500000"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"14A5mPi7oJGQ","colab_type":"text"},"source":["OK, great! Now we have replaced the useless NaN values with the average height. While this obviously isn't as good as original data, in a lot of situations this can be a step up from losing rows entirely. "]},{"cell_type":"markdown","metadata":{"id":"DK7eW8caoJGR","colab_type":"text"},"source":["Sophisticated analysis can be done in only a few lines using Pandas. Let's say that we want to get the average coffee rating by country. First, we can use the `groupby` method to automatically collect the results by country. Then, we can select the column we want - `quality_score` - and calculate its mean the same way we would using NumPy:"]},{"cell_type":"code","metadata":{"id":"xx0KTeIxoJGR","colab_type":"code","outputId":"11ffd89b-b60a-4c10-c3c7-0f683dd81eac","executionInfo":{"status":"ok","timestamp":1572099830275,"user_tz":240,"elapsed":11294,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["df_clean.groupby('Country of Origin')['quality_score'].mean()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Country of Origin\n","Brazil                          82.330725\n","China                           80.868000\n","Colombia                        82.932000\n","Costa Rica                      83.090000\n","El Salvador                     82.804545\n","Ethiopia                        87.792500\n","Guatemala                       81.957832\n","Haiti                           80.750000\n","Honduras                        81.010476\n","Indonesia                       81.524286\n","Kenya                           85.415000\n","Laos                            82.000000\n","Malawi                          81.711818\n","Mexico                          80.246087\n","Myanmar                         80.666667\n","Nicaragua                       79.333000\n","Panama                          81.750000\n","Peru                            77.000000\n","Philippines                     80.312500\n","Taiwan                          82.462895\n","Tanzania, United Republic Of    82.411724\n","Uganda                          83.778333\n","Name: quality_score, dtype: float64"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"Jzvh5MU-oJGS","colab_type":"text"},"source":["This is certainly interesting, but it could be presented better. First, all of the ratings are pretty high (what's the highest and lowest rating?). Let's standardize to unit mean and variance so that we can tell the difference more easily. We'll just do that on our subset here for now, but you can apply it to the entire dataset too!"]},{"cell_type":"code","metadata":{"id":"CBUOQRA9oJGS","colab_type":"code","outputId":"328db616-8602-45eb-97fa-c94ec619211e","executionInfo":{"status":"ok","timestamp":1572099830275,"user_tz":240,"elapsed":11288,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["country_means = df_clean.groupby('Country of Origin')['quality_score'].mean()\n","mu,si = country_means.mean(), country_means.std() #Calculate the overall mean and standard deviation of the quality scores\n","country_means -= mu #Subtract the mean from every entry\n","country_means /= si #Divide every entry by the standard deviation\n","country_means"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Country of Origin\n","Brazil                          0.194625\n","China                          -0.491541\n","Colombia                        0.476684\n","Costa Rica                      0.550802\n","El Salvador                     0.416895\n","Ethiopia                        2.756749\n","Guatemala                       0.019701\n","Haiti                          -0.546895\n","Honduras                       -0.424705\n","Indonesia                      -0.183677\n","Kenya                           1.641462\n","Laos                            0.039482\n","Malawi                         -0.095705\n","Mexico                         -0.783281\n","Myanmar                        -0.585987\n","Nicaragua                      -1.211611\n","Panama                         -0.077794\n","Peru                           -2.306024\n","Philippines                    -0.752127\n","Taiwan                          0.256626\n","Tanzania, United Republic Of    0.232622\n","Uganda                          0.873700\n","Name: quality_score, dtype: float64"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"2dFpdBvuoJGU","colab_type":"text"},"source":["This is a lot clearer! Finally, let's sort this list so that it's easier to compare entries."]},{"cell_type":"code","metadata":{"id":"Ij1F28KzoJGU","colab_type":"code","outputId":"6ce1c4ea-5767-4b69-c995-662930762d61","executionInfo":{"status":"ok","timestamp":1572099830276,"user_tz":240,"elapsed":11283,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["country_means.sort_values()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Country of Origin\n","Peru                           -2.306024\n","Nicaragua                      -1.211611\n","Mexico                         -0.783281\n","Philippines                    -0.752127\n","Myanmar                        -0.585987\n","Haiti                          -0.546895\n","China                          -0.491541\n","Honduras                       -0.424705\n","Indonesia                      -0.183677\n","Malawi                         -0.095705\n","Panama                         -0.077794\n","Guatemala                       0.019701\n","Laos                            0.039482\n","Brazil                          0.194625\n","Tanzania, United Republic Of    0.232622\n","Taiwan                          0.256626\n","El Salvador                     0.416895\n","Colombia                        0.476684\n","Costa Rica                      0.550802\n","Uganda                          0.873700\n","Kenya                           1.641462\n","Ethiopia                        2.756749\n","Name: quality_score, dtype: float64"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"NoMBMddpoJGW","colab_type":"text"},"source":["Finally, we'll look at indexing using Pandas. Let's say that we want to only look at the coffee entries from Taiwan. We can use the following syntax to identify those rows:"]},{"cell_type":"code","metadata":{"id":"Rft2VN4soJGW","colab_type":"code","outputId":"bee16640-ab79-4499-f6d7-715ddaf87125","executionInfo":{"status":"ok","timestamp":1572099830277,"user_tz":240,"elapsed":11277,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["df_clean[df_clean['Country of Origin'] == 'Taiwan']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Bag Weight</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Color</th>\n","      <th>Company</th>\n","      <th>Country of Origin</th>\n","      <th>Cupper Points</th>\n","      <th>Expiration</th>\n","      <th>Farm Name</th>\n","      <th>Flavor</th>\n","      <th>Grading Date</th>\n","      <th>Harvest Year</th>\n","      <th>ICO Number</th>\n","      <th>In-Country Partner</th>\n","      <th>Mill</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Processing Method</th>\n","      <th>Producer</th>\n","      <th>Region</th>\n","      <th>Species</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>Variety</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>29</th>\n","      <td>29</td>\n","      <td>8.25</td>\n","      <td>8.00</td>\n","      <td>8.00</td>\n","      <td>50 kg</td>\n","      <td>8.17</td>\n","      <td>8.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.17</td>\n","      <td>May 18th, 2017</td>\n","      <td>Tsoustructive Garden 鄒築園</td>\n","      <td>8.00</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tsoustructive garden 鄒築園</td>\n","      <td>0.00</td>\n","      <td>20</td>\n","      <td>Pulped natural / honey</td>\n","      <td>FANG,ZHENG-LUN 方政倫</td>\n","      <td>leye, alishan township, chiayi county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Sumatra</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>86.58</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>43</td>\n","      <td>8.08</td>\n","      <td>7.75</td>\n","      <td>8.08</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.42</td>\n","      <td>June 9th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>8.17</td>\n","      <td>June 10th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Semi-washed / Semi-pulped</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>86.08</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>108</td>\n","      <td>7.58</td>\n","      <td>8.00</td>\n","      <td>7.67</td>\n","      <td>40 kg</td>\n","      <td>7.92</td>\n","      <td>8.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.92</td>\n","      <td>June 8th, 2016</td>\n","      <td>Baishengcun Coffee 百勝村咖啡莊園</td>\n","      <td>7.83</td>\n","      <td>June 9th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baishengcun coffee 百勝村咖啡莊園</td>\n","      <td>0.11</td>\n","      <td>20</td>\n","      <td>Semi-washed / Semi-pulped</td>\n","      <td>SU CHUEN SHIAN 蘇春賢</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>84.92</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>115</td>\n","      <td>7.83</td>\n","      <td>7.83</td>\n","      <td>7.92</td>\n","      <td>20 kg</td>\n","      <td>7.83</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.00</td>\n","      <td>May 18th, 2017</td>\n","      <td>Shi Fang Yuan 十方源</td>\n","      <td>7.58</td>\n","      <td>May 18th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>shi fang yuan 十方源</td>\n","      <td>0.00</td>\n","      <td>10</td>\n","      <td>Natural / Dry</td>\n","      <td>Wang Chao Yung 王超永</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>84.83</td>\n","    </tr>\n","    <tr>\n","      <th>175</th>\n","      <td>175</td>\n","      <td>8.00</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>2 kg</td>\n","      <td>7.75</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>tropica galliard</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>July 10th, 2014</td>\n","      <td>Tropica Galliard</td>\n","      <td>7.83</td>\n","      <td>July 10th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tropica galliard</td>\n","      <td>0.11</td>\n","      <td>2</td>\n","      <td>Washed / Wet</td>\n","      <td>Kao Ming Lee</td>\n","      <td>mountain ali, taiwan</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>84.42</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>191</td>\n","      <td>7.67</td>\n","      <td>7.75</td>\n","      <td>7.92</td>\n","      <td>5 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.67</td>\n","      <td>August 10th, 2018</td>\n","      <td>馨晴咖啡 Good Mood Coffee</td>\n","      <td>7.75</td>\n","      <td>August 10th, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>馨晴咖啡 good mood coffee</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>黃美桃 Huang Mei Tao</td>\n","      <td>國姓鄉 guoshing township</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>84.25</td>\n","    </tr>\n","    <tr>\n","      <th>233</th>\n","      <td>233</td>\n","      <td>7.67</td>\n","      <td>7.67</td>\n","      <td>7.58</td>\n","      <td>20 kg</td>\n","      <td>7.83</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.92</td>\n","      <td>May 18th, 2017</td>\n","      <td>CHANG YU LIANG 張玉良</td>\n","      <td>7.67</td>\n","      <td>May 18th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>chang yu liang 張玉良</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>CHANG YU LIANG 張玉良</td>\n","      <td>nanxi dist., tainan city 臺南市楠西區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>968.00</td>\n","      <td>968.00</td>\n","      <td>968.00</td>\n","      <td>84.08</td>\n","    </tr>\n","    <tr>\n","      <th>262</th>\n","      <td>262</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>7.83</td>\n","      <td>50 kg</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.83</td>\n","      <td>May 18th, 2017</td>\n","      <td>Tsoustructive Garden 鄒築園</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tsoustructive garden 鄒築園</td>\n","      <td>0.11</td>\n","      <td>20</td>\n","      <td>Washed / Wet</td>\n","      <td>FANG,ZHENG-LUN 方政倫</td>\n","      <td>leye, alishan township, chiayi county 嘉義阿里山樂野村</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>83.92</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>269</td>\n","      <td>7.92</td>\n","      <td>7.92</td>\n","      <td>8.00</td>\n","      <td>60 kg</td>\n","      <td>7.33</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.17</td>\n","      <td>November 23rd, 2015</td>\n","      <td>神谷山莊園</td>\n","      <td>7.92</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>神谷山莊園</td>\n","      <td>0.06</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>張瑞宏</td>\n","      <td>台中和平區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>950.00</td>\n","      <td>950.00</td>\n","      <td>950.00</td>\n","      <td>83.92</td>\n","    </tr>\n","    <tr>\n","      <th>280</th>\n","      <td>280</td>\n","      <td>7.75</td>\n","      <td>7.67</td>\n","      <td>7.67</td>\n","      <td>18 kg</td>\n","      <td>7.75</td>\n","      <td>7.42</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.83</td>\n","      <td>April 29th, 2016</td>\n","      <td>鄉舍咖啡 Hometown Coffee</td>\n","      <td>7.75</td>\n","      <td>April 30th, 2015</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>鄉舍咖啡 hometown coffee</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>Washed / Wet</td>\n","      <td>ZENG JIAN NAN 曾建男</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>570.00</td>\n","      <td>480.00</td>\n","      <td>525.00</td>\n","      <td>83.83</td>\n","    </tr>\n","    <tr>\n","      <th>298</th>\n","      <td>298</td>\n","      <td>7.58</td>\n","      <td>7.58</td>\n","      <td>7.67</td>\n","      <td>10 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>June 6th, 2018</td>\n","      <td>崁頭山咖啡館 (Kan Tou Mountain Coffee)</td>\n","      <td>7.67</td>\n","      <td>June 6th, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>崁頭山咖啡館 (kan tou mountain coffee)</td>\n","      <td>0.00</td>\n","      <td>10</td>\n","      <td>Natural / Dry</td>\n","      <td>曾如楓 &amp; 郭俊宏 (Tseng Ju Feng &amp; Kuo Jun Hong)</td>\n","      <td>台南市東山區 (dongshan dist., tainan city)</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>750.00</td>\n","      <td>750.00</td>\n","      <td>750.00</td>\n","      <td>83.75</td>\n","    </tr>\n","    <tr>\n","      <th>319</th>\n","      <td>319</td>\n","      <td>7.92</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>50 kg</td>\n","      <td>7.67</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2017</td>\n","      <td>Tsoustructive Garden 鄒築園</td>\n","      <td>7.67</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>tsoustructive garden 鄒築園</td>\n","      <td>0.10</td>\n","      <td>20</td>\n","      <td>Natural / Dry</td>\n","      <td>FANG,ZHENG-LUN 方政倫</td>\n","      <td>leye, alishan township, chiayi county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Caturra</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>83.67</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>425</td>\n","      <td>7.50</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>June 17th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>7.50</td>\n","      <td>June 18th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>83.25</td>\n","    </tr>\n","    <tr>\n","      <th>426</th>\n","      <td>426</td>\n","      <td>7.58</td>\n","      <td>7.75</td>\n","      <td>7.92</td>\n","      <td>60 kg</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>November 23rd, 2015</td>\n","      <td>以勒咖啡</td>\n","      <td>7.83</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwanw台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>以勒咖啡</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>蘇詠晴</td>\n","      <td>南投國姓</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>83.25</td>\n","    </tr>\n","    <tr>\n","      <th>483</th>\n","      <td>483</td>\n","      <td>7.83</td>\n","      <td>7.50</td>\n","      <td>7.83</td>\n","      <td>60 kg</td>\n","      <td>7.25</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2016</td>\n","      <td>Kan Tou Mountain Coffee 崁頭山咖啡館</td>\n","      <td>7.92</td>\n","      <td>May 19th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>kan tou mountain coffee 崁頭山咖啡館</td>\n","      <td>0.00</td>\n","      <td>20</td>\n","      <td>Natural / Dry</td>\n","      <td>Tseng ju feng / Kuo jun hong 曾如楓 / 郭俊宏</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>700.00</td>\n","      <td>750.00</td>\n","      <td>83.08</td>\n","    </tr>\n","    <tr>\n","      <th>508</th>\n","      <td>508</td>\n","      <td>7.58</td>\n","      <td>7.83</td>\n","      <td>7.92</td>\n","      <td>60 kg</td>\n","      <td>7.25</td>\n","      <td>7.33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.17</td>\n","      <td>November 23rd, 2015</td>\n","      <td>雅慕伊</td>\n","      <td>7.92</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>雅慕伊</td>\n","      <td>0.08</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>雅慕伊</td>\n","      <td>嘉義阿里山</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>83.00</td>\n","    </tr>\n","    <tr>\n","      <th>536</th>\n","      <td>536</td>\n","      <td>7.67</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>20 kg</td>\n","      <td>7.58</td>\n","      <td>7.67</td>\n","      <td>31</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>June 28th, 2017</td>\n","      <td>Shi Fang Yuan 十方源</td>\n","      <td>7.83</td>\n","      <td>June 28th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>shi fang yuan 十方源</td>\n","      <td>0.09</td>\n","      <td>10</td>\n","      <td>Natural / Dry</td>\n","      <td>Wang Chao Yung 王超永</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Caturra</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>350.00</td>\n","      <td>82.92</td>\n","    </tr>\n","    <tr>\n","      <th>538</th>\n","      <td>538</td>\n","      <td>7.33</td>\n","      <td>7.67</td>\n","      <td>7.50</td>\n","      <td>2 kg</td>\n","      <td>7.75</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>September 6th, 2016</td>\n","      <td>佐佑品咖啡莊園</td>\n","      <td>7.58</td>\n","      <td>September 7th, 2015</td>\n","      <td>2014</td>\n","      <td>123</td>\n","      <td>Blossom Valley International</td>\n","      <td>誼鎂有限公司</td>\n","      <td>0.00</td>\n","      <td>11</td>\n","      <td>Natural / Dry</td>\n","      <td>許文郎</td>\n","      <td>台東太麻里</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>775.00</td>\n","      <td>775.00</td>\n","      <td>775.00</td>\n","      <td>82.92</td>\n","    </tr>\n","    <tr>\n","      <th>585</th>\n","      <td>585</td>\n","      <td>7.67</td>\n","      <td>7.33</td>\n","      <td>7.83</td>\n","      <td>10 kg</td>\n","      <td>7.67</td>\n","      <td>7.58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.67</td>\n","      <td>June 1st, 2018</td>\n","      <td>大鋤花間 (HOE Vs. FLOWER COFFEE FARM)</td>\n","      <td>7.67</td>\n","      <td>June 1st, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>大鋤花間 (hoe vs. flower coffee farm)</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>Natural / Dry</td>\n","      <td>林俊吉( Lin, Chun-Chi)</td>\n","      <td>台南市東山區( dongshan dist., tainan city)</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Yellow Bourbon</td>\n","      <td>650.00</td>\n","      <td>650.00</td>\n","      <td>650.00</td>\n","      <td>82.75</td>\n","    </tr>\n","    <tr>\n","      <th>617</th>\n","      <td>617</td>\n","      <td>7.42</td>\n","      <td>7.83</td>\n","      <td>8.00</td>\n","      <td>60 kg</td>\n","      <td>7.25</td>\n","      <td>7.25</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.08</td>\n","      <td>November 23rd, 2015</td>\n","      <td>伊娜咖啡莊園</td>\n","      <td>7.83</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>伊娜咖啡莊園</td>\n","      <td>0.08</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>林道明</td>\n","      <td>嘉義阿里山</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>1200.00</td>\n","      <td>82.67</td>\n","    </tr>\n","    <tr>\n","      <th>634</th>\n","      <td>634</td>\n","      <td>7.42</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>5 kg</td>\n","      <td>7.50</td>\n","      <td>7.58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.50</td>\n","      <td>August 22nd, 2018</td>\n","      <td>林園咖啡 Lin Yuan Coffee</td>\n","      <td>7.42</td>\n","      <td>August 22nd, 2017</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>林園咖啡 lin yuan coffee</td>\n","      <td>0.11</td>\n","      <td>6</td>\n","      <td>Pulped natural / honey</td>\n","      <td>林文弘 Lin Wen Hong</td>\n","      <td>國姓鄉 guoshing township</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>1050.00</td>\n","      <td>1050.00</td>\n","      <td>1050.00</td>\n","      <td>82.58</td>\n","    </tr>\n","    <tr>\n","      <th>770</th>\n","      <td>770</td>\n","      <td>7.17</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>10 kg</td>\n","      <td>7.58</td>\n","      <td>7.17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>May 29th, 2014</td>\n","      <td>Kan Tou Mountain Coffee 崁頭山咖啡館</td>\n","      <td>7.50</td>\n","      <td>May 29th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>kan tou mountain coffee 崁頭山咖啡館</td>\n","      <td>0.00</td>\n","      <td>80</td>\n","      <td>Washed / Wet</td>\n","      <td>Jufeng-Tseng 曾如楓</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>82.17</td>\n","    </tr>\n","    <tr>\n","      <th>801</th>\n","      <td>801</td>\n","      <td>7.42</td>\n","      <td>7.17</td>\n","      <td>7.33</td>\n","      <td>20 kg</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.75</td>\n","      <td>July 22nd, 2015</td>\n","      <td>You Siang Coffee FarmTainan, Taiwan 台灣台南優香咖啡</td>\n","      <td>7.50</td>\n","      <td>July 22nd, 2014</td>\n","      <td>2013</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>you siang coffee farmtainan, taiwan 台灣台南優香咖啡</td>\n","      <td>0.09</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>Chen Jin Lin 陳金璘</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>82.00</td>\n","    </tr>\n","    <tr>\n","      <th>806</th>\n","      <td>806</td>\n","      <td>7.42</td>\n","      <td>7.33</td>\n","      <td>7.42</td>\n","      <td>10 kg</td>\n","      <td>7.50</td>\n","      <td>8.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.42</td>\n","      <td>June 3rd, 2014</td>\n","      <td>Gao Chun Fang 高醇坊</td>\n","      <td>7.58</td>\n","      <td>June 3rd, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>gao chun fang 高醇坊</td>\n","      <td>0.12</td>\n","      <td>30</td>\n","      <td>Washed / Wet</td>\n","      <td>Lin Huang, A-Mien 黃阿綿</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>700.00</td>\n","      <td>600.00</td>\n","      <td>650.00</td>\n","      <td>82.00</td>\n","    </tr>\n","    <tr>\n","      <th>844</th>\n","      <td>844</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>7.67</td>\n","      <td>5 kg</td>\n","      <td>7.33</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>April 29th, 2016</td>\n","      <td>Gao Chun Fang 高醇坊</td>\n","      <td>7.33</td>\n","      <td>April 30th, 2015</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>gao chun fang 高醇坊</td>\n","      <td>0.00</td>\n","      <td>8</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN SIN JI 林信吉</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>700.00</td>\n","      <td>700.00</td>\n","      <td>700.00</td>\n","      <td>81.83</td>\n","    </tr>\n","    <tr>\n","      <th>897</th>\n","      <td>897</td>\n","      <td>7.67</td>\n","      <td>7.25</td>\n","      <td>7.42</td>\n","      <td>50 kg</td>\n","      <td>7.25</td>\n","      <td>7.33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.25</td>\n","      <td>July 15th, 2017</td>\n","      <td>Baishengcun Coffee 百勝村咖啡莊園</td>\n","      <td>7.42</td>\n","      <td>July 15th, 2016</td>\n","      <td>2016</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baishengcun coffee 百勝村咖啡莊園</td>\n","      <td>0.10</td>\n","      <td>20</td>\n","      <td>Washed / Wet</td>\n","      <td>蘇晉寬 Su Jin Kuan</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>81.58</td>\n","    </tr>\n","    <tr>\n","      <th>914</th>\n","      <td>914</td>\n","      <td>7.08</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>2 kg</td>\n","      <td>7.25</td>\n","      <td>7.58</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>September 16th, 2016</td>\n","      <td>谷泉咖啡莊園</td>\n","      <td>7.42</td>\n","      <td>September 17th, 2015</td>\n","      <td>2015</td>\n","      <td>123</td>\n","      <td>Blossom Valley International</td>\n","      <td>寶島咖啡</td>\n","      <td>0.12</td>\n","      <td>123</td>\n","      <td>Natural / Dry</td>\n","      <td>劉易騰</td>\n","      <td>古坑鄉荷包村尖山坑60號</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>200.00</td>\n","      <td>160.00</td>\n","      <td>180.00</td>\n","      <td>81.50</td>\n","    </tr>\n","    <tr>\n","      <th>919</th>\n","      <td>919</td>\n","      <td>7.33</td>\n","      <td>7.67</td>\n","      <td>7.42</td>\n","      <td>20 kg</td>\n","      <td>7.50</td>\n","      <td>7.42</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.50</td>\n","      <td>August 18th, 2015</td>\n","      <td>Good Mood Coffee 馨晴咖啡</td>\n","      <td>7.33</td>\n","      <td>August 18th, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>good mood coffee 馨晴咖啡</td>\n","      <td>0.11</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>HUANG MEI TAO 黃美桃</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>9.33</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>900.00</td>\n","      <td>81.50</td>\n","    </tr>\n","    <tr>\n","      <th>938</th>\n","      <td>938</td>\n","      <td>7.17</td>\n","      <td>7.42</td>\n","      <td>7.83</td>\n","      <td>60 kg</td>\n","      <td>7.08</td>\n","      <td>7.08</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.08</td>\n","      <td>November 23rd, 2015</td>\n","      <td>山彎有機咖啡農場</td>\n","      <td>7.75</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>三彎農會</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>謝文品</td>\n","      <td>苗栗三灣</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>110.00</td>\n","      <td>110.00</td>\n","      <td>110.00</td>\n","      <td>81.42</td>\n","    </tr>\n","    <tr>\n","      <th>962</th>\n","      <td>962</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>7.83</td>\n","      <td>50 kg</td>\n","      <td>7.75</td>\n","      <td>7.83</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>5.25</td>\n","      <td>May 18th, 2017</td>\n","      <td>Jing Jing Café 晶晶坊青山咖啡教室</td>\n","      <td>7.75</td>\n","      <td>May 18th, 2016</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>jing jing café 晶晶坊青山咖啡教室</td>\n","      <td>0.12</td>\n","      <td>20</td>\n","      <td>Natural / Dry</td>\n","      <td>Hu Guei Jing 胡桂青</td>\n","      <td>dongshan dist., tainan city 台南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>9.33</td>\n","      <td>Typica</td>\n","      <td>680.00</td>\n","      <td>680.00</td>\n","      <td>680.00</td>\n","      <td>81.25</td>\n","    </tr>\n","    <tr>\n","      <th>1004</th>\n","      <td>1004</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>7.25</td>\n","      <td>5 kg</td>\n","      <td>7.33</td>\n","      <td>7.50</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Bluish-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.33</td>\n","      <td>May 5th, 2016</td>\n","      <td>Jing Jing Café 晶晶坊青山咖啡教室</td>\n","      <td>7.17</td>\n","      <td>May 6th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>jing jing café 晶晶坊青山咖啡教室</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>HU KUEI CHING 胡桂青</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>758.00</td>\n","      <td>758.00</td>\n","      <td>758.00</td>\n","      <td>81.00</td>\n","    </tr>\n","    <tr>\n","      <th>1021</th>\n","      <td>1021</td>\n","      <td>7.08</td>\n","      <td>7.33</td>\n","      <td>7.92</td>\n","      <td>60 kg</td>\n","      <td>7.08</td>\n","      <td>7.08</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>6.75</td>\n","      <td>November 23rd, 2015</td>\n","      <td>張文進莊園</td>\n","      <td>7.67</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>張文進莊園</td>\n","      <td>0.09</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>張文進</td>\n","      <td>台中新社</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>550.00</td>\n","      <td>550.00</td>\n","      <td>550.00</td>\n","      <td>80.92</td>\n","    </tr>\n","    <tr>\n","      <th>1080</th>\n","      <td>1080</td>\n","      <td>7.17</td>\n","      <td>7.17</td>\n","      <td>7.58</td>\n","      <td>60 kg</td>\n","      <td>7.17</td>\n","      <td>7.17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.00</td>\n","      <td>November 23rd, 2015</td>\n","      <td>春風咖啡</td>\n","      <td>7.17</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>春風咖啡</td>\n","      <td>0.14</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>曾林春英</td>\n","      <td>南投國姓</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>600.00</td>\n","      <td>80.42</td>\n","    </tr>\n","    <tr>\n","      <th>1115</th>\n","      <td>1115</td>\n","      <td>7.17</td>\n","      <td>7.25</td>\n","      <td>7.42</td>\n","      <td>60 kg</td>\n","      <td>7.00</td>\n","      <td>7.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>宸嶧國際</td>\n","      <td>Taiwan</td>\n","      <td>7.00</td>\n","      <td>November 23rd, 2015</td>\n","      <td>好自在咖啡莊園</td>\n","      <td>7.25</td>\n","      <td>November 23rd, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan台灣</td>\n","      <td>Blossom Valley International</td>\n","      <td>好自在咖啡莊園</td>\n","      <td>0.07</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>簡義榮</td>\n","      <td>苗栗泰安</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>80.08</td>\n","    </tr>\n","    <tr>\n","      <th>1146</th>\n","      <td>1146</td>\n","      <td>7.00</td>\n","      <td>7.25</td>\n","      <td>7.08</td>\n","      <td>20 kg</td>\n","      <td>7.17</td>\n","      <td>7.17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>7.00</td>\n","      <td>July 28th, 2015</td>\n","      <td>Baijiada Coffee Farm佰加達咖啡莊園</td>\n","      <td>7.08</td>\n","      <td>July 28th, 2014</td>\n","      <td>2013</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baijiada coffee farm佰加達咖啡莊園</td>\n","      <td>0.10</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN REN FU 林人富</td>\n","      <td>baihe dist., tainan city 臺南市白河區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>700.00</td>\n","      <td>500.00</td>\n","      <td>600.00</td>\n","      <td>79.75</td>\n","    </tr>\n","    <tr>\n","      <th>1182</th>\n","      <td>1182</td>\n","      <td>7.25</td>\n","      <td>6.83</td>\n","      <td>7.08</td>\n","      <td>20 kg</td>\n","      <td>7.08</td>\n","      <td>7.42</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>6.75</td>\n","      <td>November 7th, 2015</td>\n","      <td>BaiShenCun Coffee Farm百勝村咖啡莊園</td>\n","      <td>6.83</td>\n","      <td>November 7th, 2014</td>\n","      <td>2014</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>baishengcun coffee 百勝村咖啡莊園</td>\n","      <td>0.11</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>WU SHU YI 巫叔憶</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>850.00</td>\n","      <td>79.25</td>\n","    </tr>\n","    <tr>\n","      <th>1217</th>\n","      <td>1217</td>\n","      <td>7.25</td>\n","      <td>7.17</td>\n","      <td>6.83</td>\n","      <td>20 kg</td>\n","      <td>6.92</td>\n","      <td>7.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>red on tree co., ltd.</td>\n","      <td>Taiwan</td>\n","      <td>6.67</td>\n","      <td>July 22nd, 2015</td>\n","      <td>Kan Tou Mountain Coffee 崁頭山咖啡館</td>\n","      <td>6.75</td>\n","      <td>July 22nd, 2014</td>\n","      <td>2013</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>kan tou mountain coffee 崁頭山咖啡館</td>\n","      <td>0.10</td>\n","      <td>50</td>\n","      <td>Washed / Wet</td>\n","      <td>GUO JIUN HUNG 郭俊宏 &amp; TSENG RU FENG 曾如楓</td>\n","      <td>dongshan dist., tainan city 臺南市東山區</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Typica</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>800.00</td>\n","      <td>78.58</td>\n","    </tr>\n","    <tr>\n","      <th>1249</th>\n","      <td>1249</td>\n","      <td>7.17</td>\n","      <td>6.67</td>\n","      <td>7.00</td>\n","      <td>10 kg</td>\n","      <td>6.83</td>\n","      <td>6.83</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>9.33</td>\n","      <td>Green</td>\n","      <td>unex guatemala, s.a.</td>\n","      <td>Taiwan</td>\n","      <td>6.67</td>\n","      <td>February 7th, 2014</td>\n","      <td>Dongshan Gaoyuan village chief manor coffee Ta...</td>\n","      <td>6.83</td>\n","      <td>May 29th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>beneficio ixchel</td>\n","      <td>0.11</td>\n","      <td>100</td>\n","      <td>Washed / Wet</td>\n","      <td>LUIS RODRIGUEZ</td>\n","      <td>oriente</td>\n","      <td>Arabica</td>\n","      <td>10.00</td>\n","      <td>10.00</td>\n","      <td>Bourbon</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>77.67</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0  Acidity  ...  altitude_mean_meters  quality_score\n","29            29     8.25  ...               1200.00          86.58\n","43            43     8.08  ...               1000.00          86.08\n","108          108     7.58  ...                800.00          84.92\n","115          115     7.83  ...                350.00          84.83\n","175          175     8.00  ...               1200.00          84.42\n","191          191     7.67  ...               1000.00          84.25\n","233          233     7.67  ...                968.00          84.08\n","262          262     7.75  ...               1200.00          83.92\n","269          269     7.92  ...                950.00          83.92\n","280          280     7.75  ...                525.00          83.83\n","298          298     7.58  ...                750.00          83.75\n","319          319     7.92  ...               1200.00          83.67\n","425          425     7.50  ...               1000.00          83.25\n","426          426     7.58  ...                800.00          83.25\n","483          483     7.83  ...                750.00          83.08\n","508          508     7.58  ...               1200.00          83.00\n","536          536     7.67  ...                350.00          82.92\n","538          538     7.33  ...                775.00          82.92\n","585          585     7.67  ...                650.00          82.75\n","617          617     7.42  ...               1200.00          82.67\n","634          634     7.42  ...               1050.00          82.58\n","770          770     7.17  ...                800.00          82.17\n","801          801     7.42  ...                600.00          82.00\n","806          806     7.42  ...                650.00          82.00\n","844          844     7.25  ...                700.00          81.83\n","897          897     7.67  ...                800.00          81.58\n","914          914     7.08  ...                180.00          81.50\n","919          919     7.33  ...                900.00          81.50\n","938          938     7.17  ...                110.00          81.42\n","962          962     7.83  ...                680.00          81.25\n","1004        1004     7.25  ...                758.00          81.00\n","1021        1021     7.08  ...                550.00          80.92\n","1080        1080     7.17  ...                600.00          80.42\n","1115        1115     7.17  ...                850.00          80.08\n","1146        1146     7.00  ...                600.00          79.75\n","1182        1182     7.25  ...                850.00          79.25\n","1217        1217     7.25  ...                800.00          78.58\n","1249        1249     7.17  ...               1310.64          77.67\n","\n","[38 rows x 35 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Pdy7AhiboJGY","colab_type":"text"},"source":["Say that out of the Taiwanese coffees, we only want to look at those which are the Bourbon variety. We can also chain those indexing operations like so:"]},{"cell_type":"code","metadata":{"id":"fK2anT_loJGY","colab_type":"code","outputId":"547bb5d0-a054-48e3-fc3d-66d5221d74bd","executionInfo":{"status":"ok","timestamp":1572099830277,"user_tz":240,"elapsed":11271,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":468}},"source":["df_clean[df_clean['Country of Origin'] == 'Taiwan'][df_clean['Variety'] == 'Bourbon']"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Acidity</th>\n","      <th>Aftertaste</th>\n","      <th>Aroma</th>\n","      <th>Bag Weight</th>\n","      <th>Balance</th>\n","      <th>Body</th>\n","      <th>Category.One.Defects</th>\n","      <th>Category.Two.Defects</th>\n","      <th>Clean Cup</th>\n","      <th>Color</th>\n","      <th>Company</th>\n","      <th>Country of Origin</th>\n","      <th>Cupper Points</th>\n","      <th>Expiration</th>\n","      <th>Farm Name</th>\n","      <th>Flavor</th>\n","      <th>Grading Date</th>\n","      <th>Harvest Year</th>\n","      <th>ICO Number</th>\n","      <th>In-Country Partner</th>\n","      <th>Mill</th>\n","      <th>Moisture</th>\n","      <th>Number of Bags</th>\n","      <th>Processing Method</th>\n","      <th>Producer</th>\n","      <th>Region</th>\n","      <th>Species</th>\n","      <th>Sweetness</th>\n","      <th>Uniformity</th>\n","      <th>Variety</th>\n","      <th>altitude_high_meters</th>\n","      <th>altitude_low_meters</th>\n","      <th>altitude_mean_meters</th>\n","      <th>quality_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>43</th>\n","      <td>43</td>\n","      <td>8.08</td>\n","      <td>7.75</td>\n","      <td>8.08</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.75</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>8.42</td>\n","      <td>June 9th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>8.17</td>\n","      <td>June 10th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.12</td>\n","      <td>10</td>\n","      <td>Semi-washed / Semi-pulped</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.0</td>\n","      <td>10.0</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>86.08</td>\n","    </tr>\n","    <tr>\n","      <th>425</th>\n","      <td>425</td>\n","      <td>7.50</td>\n","      <td>7.50</td>\n","      <td>7.67</td>\n","      <td>15 kg</td>\n","      <td>7.83</td>\n","      <td>7.67</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.00</td>\n","      <td>Blue-Green</td>\n","      <td>taiwan coffee laboratory</td>\n","      <td>Taiwan</td>\n","      <td>7.58</td>\n","      <td>June 17th, 2016</td>\n","      <td>Sunshine Valley Estate 向陽高山咖啡</td>\n","      <td>7.50</td>\n","      <td>June 18th, 2015</td>\n","      <td>2015</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>sunshine valley estate 向陽高山咖啡</td>\n","      <td>0.10</td>\n","      <td>10</td>\n","      <td>Washed / Wet</td>\n","      <td>LIN YEN CHIEN 林言謙</td>\n","      <td>natou county</td>\n","      <td>Arabica</td>\n","      <td>10.0</td>\n","      <td>10.0</td>\n","      <td>Bourbon</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>1000.00</td>\n","      <td>83.25</td>\n","    </tr>\n","    <tr>\n","      <th>1249</th>\n","      <td>1249</td>\n","      <td>7.17</td>\n","      <td>6.67</td>\n","      <td>7.00</td>\n","      <td>10 kg</td>\n","      <td>6.83</td>\n","      <td>6.83</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>9.33</td>\n","      <td>Green</td>\n","      <td>unex guatemala, s.a.</td>\n","      <td>Taiwan</td>\n","      <td>6.67</td>\n","      <td>February 7th, 2014</td>\n","      <td>Dongshan Gaoyuan village chief manor coffee Ta...</td>\n","      <td>6.83</td>\n","      <td>May 29th, 2013</td>\n","      <td>2012</td>\n","      <td>Taiwan</td>\n","      <td>Specialty Coffee Association</td>\n","      <td>beneficio ixchel</td>\n","      <td>0.11</td>\n","      <td>100</td>\n","      <td>Washed / Wet</td>\n","      <td>LUIS RODRIGUEZ</td>\n","      <td>oriente</td>\n","      <td>Arabica</td>\n","      <td>10.0</td>\n","      <td>10.0</td>\n","      <td>Bourbon</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>1310.64</td>\n","      <td>77.67</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0  Acidity  ...  altitude_mean_meters  quality_score\n","43            43     8.08  ...               1000.00          86.08\n","425          425     7.50  ...               1000.00          83.25\n","1249        1249     7.17  ...               1310.64          77.67\n","\n","[3 rows x 35 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"JghslLyIoJGZ","colab_type":"text"},"source":["### Scikit-learn Basics\n","\n","Scikit-learn is a great library to use for doing machine learning in Python. Data preparation, exploratory data analysis (EDA), classification, regression, clustering; it has it all. \n","\n","Scikit-learn usually expects data to be in the form of a 2D matrix with dimensions *n_samples x n_features* with an additional column for the target. To get acquainted with scikit-learn, we are going to use the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris), one of the most famous datasets in pattern recognition. \n","\n","Each entry in the dataset represents an iris plant, and is categorized as: \n","\n","* Setosa (class 0)\n","* Versicolor (class 1)\n","* Virginica (class 2)\n","\n","These represent the target classes to predict. Each entry also includes a set of features, namely:\n","\n","* Sepal width (cm)\n","* Sepal length (cm)\n","* Petal length (cm)\n","* Petal width (cm)\n","\n","In the context of machine learning classification, the remainder of the lab is going to investigate the following question:  \n","*Can we design a model that, based on the iris sample features, can accurately predict the iris sample class? *\n","\n","Scikit-learn has a copy of the iris dataset readily importable for us. Let's grab it now and conduct some EDA."]},{"cell_type":"code","metadata":{"id":"flfiIhwgoJGa","colab_type":"code","outputId":"9e8b734b-d517-453f-d237-0b208b6f61ce","executionInfo":{"status":"ok","timestamp":1572099830279,"user_tz":240,"elapsed":11267,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from sklearn.datasets import load_iris\n","iris_data = load_iris()\n","feature_data = iris_data.data\n","\n","iris_data"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n"," 'data': array([[5.1, 3.5, 1.4, 0.2],\n","        [4.9, 3. , 1.4, 0.2],\n","        [4.7, 3.2, 1.3, 0.2],\n","        [4.6, 3.1, 1.5, 0.2],\n","        [5. , 3.6, 1.4, 0.2],\n","        [5.4, 3.9, 1.7, 0.4],\n","        [4.6, 3.4, 1.4, 0.3],\n","        [5. , 3.4, 1.5, 0.2],\n","        [4.4, 2.9, 1.4, 0.2],\n","        [4.9, 3.1, 1.5, 0.1],\n","        [5.4, 3.7, 1.5, 0.2],\n","        [4.8, 3.4, 1.6, 0.2],\n","        [4.8, 3. , 1.4, 0.1],\n","        [4.3, 3. , 1.1, 0.1],\n","        [5.8, 4. , 1.2, 0.2],\n","        [5.7, 4.4, 1.5, 0.4],\n","        [5.4, 3.9, 1.3, 0.4],\n","        [5.1, 3.5, 1.4, 0.3],\n","        [5.7, 3.8, 1.7, 0.3],\n","        [5.1, 3.8, 1.5, 0.3],\n","        [5.4, 3.4, 1.7, 0.2],\n","        [5.1, 3.7, 1.5, 0.4],\n","        [4.6, 3.6, 1. , 0.2],\n","        [5.1, 3.3, 1.7, 0.5],\n","        [4.8, 3.4, 1.9, 0.2],\n","        [5. , 3. , 1.6, 0.2],\n","        [5. , 3.4, 1.6, 0.4],\n","        [5.2, 3.5, 1.5, 0.2],\n","        [5.2, 3.4, 1.4, 0.2],\n","        [4.7, 3.2, 1.6, 0.2],\n","        [4.8, 3.1, 1.6, 0.2],\n","        [5.4, 3.4, 1.5, 0.4],\n","        [5.2, 4.1, 1.5, 0.1],\n","        [5.5, 4.2, 1.4, 0.2],\n","        [4.9, 3.1, 1.5, 0.2],\n","        [5. , 3.2, 1.2, 0.2],\n","        [5.5, 3.5, 1.3, 0.2],\n","        [4.9, 3.6, 1.4, 0.1],\n","        [4.4, 3. , 1.3, 0.2],\n","        [5.1, 3.4, 1.5, 0.2],\n","        [5. , 3.5, 1.3, 0.3],\n","        [4.5, 2.3, 1.3, 0.3],\n","        [4.4, 3.2, 1.3, 0.2],\n","        [5. , 3.5, 1.6, 0.6],\n","        [5.1, 3.8, 1.9, 0.4],\n","        [4.8, 3. , 1.4, 0.3],\n","        [5.1, 3.8, 1.6, 0.2],\n","        [4.6, 3.2, 1.4, 0.2],\n","        [5.3, 3.7, 1.5, 0.2],\n","        [5. , 3.3, 1.4, 0.2],\n","        [7. , 3.2, 4.7, 1.4],\n","        [6.4, 3.2, 4.5, 1.5],\n","        [6.9, 3.1, 4.9, 1.5],\n","        [5.5, 2.3, 4. , 1.3],\n","        [6.5, 2.8, 4.6, 1.5],\n","        [5.7, 2.8, 4.5, 1.3],\n","        [6.3, 3.3, 4.7, 1.6],\n","        [4.9, 2.4, 3.3, 1. ],\n","        [6.6, 2.9, 4.6, 1.3],\n","        [5.2, 2.7, 3.9, 1.4],\n","        [5. , 2. , 3.5, 1. ],\n","        [5.9, 3. , 4.2, 1.5],\n","        [6. , 2.2, 4. , 1. ],\n","        [6.1, 2.9, 4.7, 1.4],\n","        [5.6, 2.9, 3.6, 1.3],\n","        [6.7, 3.1, 4.4, 1.4],\n","        [5.6, 3. , 4.5, 1.5],\n","        [5.8, 2.7, 4.1, 1. ],\n","        [6.2, 2.2, 4.5, 1.5],\n","        [5.6, 2.5, 3.9, 1.1],\n","        [5.9, 3.2, 4.8, 1.8],\n","        [6.1, 2.8, 4. , 1.3],\n","        [6.3, 2.5, 4.9, 1.5],\n","        [6.1, 2.8, 4.7, 1.2],\n","        [6.4, 2.9, 4.3, 1.3],\n","        [6.6, 3. , 4.4, 1.4],\n","        [6.8, 2.8, 4.8, 1.4],\n","        [6.7, 3. , 5. , 1.7],\n","        [6. , 2.9, 4.5, 1.5],\n","        [5.7, 2.6, 3.5, 1. ],\n","        [5.5, 2.4, 3.8, 1.1],\n","        [5.5, 2.4, 3.7, 1. ],\n","        [5.8, 2.7, 3.9, 1.2],\n","        [6. , 2.7, 5.1, 1.6],\n","        [5.4, 3. , 4.5, 1.5],\n","        [6. , 3.4, 4.5, 1.6],\n","        [6.7, 3.1, 4.7, 1.5],\n","        [6.3, 2.3, 4.4, 1.3],\n","        [5.6, 3. , 4.1, 1.3],\n","        [5.5, 2.5, 4. , 1.3],\n","        [5.5, 2.6, 4.4, 1.2],\n","        [6.1, 3. , 4.6, 1.4],\n","        [5.8, 2.6, 4. , 1.2],\n","        [5. , 2.3, 3.3, 1. ],\n","        [5.6, 2.7, 4.2, 1.3],\n","        [5.7, 3. , 4.2, 1.2],\n","        [5.7, 2.9, 4.2, 1.3],\n","        [6.2, 2.9, 4.3, 1.3],\n","        [5.1, 2.5, 3. , 1.1],\n","        [5.7, 2.8, 4.1, 1.3],\n","        [6.3, 3.3, 6. , 2.5],\n","        [5.8, 2.7, 5.1, 1.9],\n","        [7.1, 3. , 5.9, 2.1],\n","        [6.3, 2.9, 5.6, 1.8],\n","        [6.5, 3. , 5.8, 2.2],\n","        [7.6, 3. , 6.6, 2.1],\n","        [4.9, 2.5, 4.5, 1.7],\n","        [7.3, 2.9, 6.3, 1.8],\n","        [6.7, 2.5, 5.8, 1.8],\n","        [7.2, 3.6, 6.1, 2.5],\n","        [6.5, 3.2, 5.1, 2. ],\n","        [6.4, 2.7, 5.3, 1.9],\n","        [6.8, 3. , 5.5, 2.1],\n","        [5.7, 2.5, 5. , 2. ],\n","        [5.8, 2.8, 5.1, 2.4],\n","        [6.4, 3.2, 5.3, 2.3],\n","        [6.5, 3. , 5.5, 1.8],\n","        [7.7, 3.8, 6.7, 2.2],\n","        [7.7, 2.6, 6.9, 2.3],\n","        [6. , 2.2, 5. , 1.5],\n","        [6.9, 3.2, 5.7, 2.3],\n","        [5.6, 2.8, 4.9, 2. ],\n","        [7.7, 2.8, 6.7, 2. ],\n","        [6.3, 2.7, 4.9, 1.8],\n","        [6.7, 3.3, 5.7, 2.1],\n","        [7.2, 3.2, 6. , 1.8],\n","        [6.2, 2.8, 4.8, 1.8],\n","        [6.1, 3. , 4.9, 1.8],\n","        [6.4, 2.8, 5.6, 2.1],\n","        [7.2, 3. , 5.8, 1.6],\n","        [7.4, 2.8, 6.1, 1.9],\n","        [7.9, 3.8, 6.4, 2. ],\n","        [6.4, 2.8, 5.6, 2.2],\n","        [6.3, 2.8, 5.1, 1.5],\n","        [6.1, 2.6, 5.6, 1.4],\n","        [7.7, 3. , 6.1, 2.3],\n","        [6.3, 3.4, 5.6, 2.4],\n","        [6.4, 3.1, 5.5, 1.8],\n","        [6. , 3. , 4.8, 1.8],\n","        [6.9, 3.1, 5.4, 2.1],\n","        [6.7, 3.1, 5.6, 2.4],\n","        [6.9, 3.1, 5.1, 2.3],\n","        [5.8, 2.7, 5.1, 1.9],\n","        [6.8, 3.2, 5.9, 2.3],\n","        [6.7, 3.3, 5.7, 2.5],\n","        [6.7, 3. , 5.2, 2.3],\n","        [6.3, 2.5, 5. , 1.9],\n","        [6.5, 3. , 5.2, 2. ],\n","        [6.2, 3.4, 5.4, 2.3],\n","        [5.9, 3. , 5.1, 1.8]]),\n"," 'feature_names': ['sepal length (cm)',\n","  'sepal width (cm)',\n","  'petal length (cm)',\n","  'petal width (cm)'],\n"," 'filename': '/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/iris.csv',\n"," 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n"," 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"k4NUSHqyoJGb","colab_type":"text"},"source":["**YOUR TURN:** \"feature_data\" now contains the feature data for all of the iris samples. \n","* What is the shape of this feature data? ___(150,4)_____________\n","* The data type? _____float64___________\n","* How many samples are there? ____150____________\n","* How many features are there? _____4___________"]},{"cell_type":"code","metadata":{"id":"Z1IHiamcoJGb","colab_type":"code","outputId":"7763cfaf-3764-4a40-eab0-ef0edaed0868","executionInfo":{"status":"ok","timestamp":1572099830279,"user_tz":240,"elapsed":11260,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["## Enter your code here\n","print (\"* The shape of this feature data is:\", feature_data.shape)\n","print (\"* The data type is:\" , feature_data.dtype.name)\n","print (\"* Number of samples are:\", feature_data.shape[0])\n","print (\"* Number of features are:\", feature_data.shape[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["* The shape of this feature data is: (150, 4)\n","* The data type is: float64\n","* Number of samples are: 150\n","* Number of features are: 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"thUa7OS70cy8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQhxUGJFoJGc","colab_type":"text"},"source":["Next, we will save the target classification data in a similar fashion."]},{"cell_type":"code","metadata":{"id":"nYUsnObIoJGc","colab_type":"code","colab":{}},"source":["target_data = iris_data.target\n","target_names = iris_data.target_names"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bnqM5ucroJGd","colab_type":"text"},"source":["**YOUR TURN:**\n","* What values are in \"target_data\"? _____{0,1,2}___________\n","* What is the data type? ____int64____________\n","* What values are in \"target_names\"? ____{'virginica', 'setosa', 'versicolor'}____________\n","* What is the data type? ___str320_________\n","* How many samples are of type \"setosa\"? _____50___________"]},{"cell_type":"code","metadata":{"id":"WFHlF8kEoJGe","colab_type":"code","outputId":"a14e0bf7-46d1-4b17-d0c7-9f3b5a1741d1","executionInfo":{"status":"ok","timestamp":1572099830281,"user_tz":240,"elapsed":11251,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["## Enter your code here\n","print (\"* The values in \\\"target_data\\\" are:\", set(target_data))\n","print (\"* The data type of \\\"target_data\\\" is:\" , target_data.dtype.name)\n","print (\"* The values in \\\"target_names\\\" are:\", set(target_names))\n","print (\"* The data type of \\\"target_names\\\":\" , target_names.dtype.name)\n","print (\"* There are \", (target_data == list(target_names).index(\"setosa\")).sum(), \"samples which are of type \\\"setosa\\\"\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["* The values in \"target_data\" are: {0, 1, 2}\n","* The data type of \"target_data\" is: int64\n","* The values in \"target_names\" are: {'versicolor', 'virginica', 'setosa'}\n","* The data type of \"target_names\": str320\n","* There are  50 samples which are of type \"setosa\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9VIjLD8RoJGf","colab_type":"text"},"source":["We can also do some more visual EDA by plotting the samples according to a subset of the features and coloring the data points to coincide with the sample classification. We will use [matplotlib](https://matplotlib.org/), a powerful plotting library within Python, to accomplish this.\n","\n","For example, lets plot sepal width vs. sepal length.\n"]},{"cell_type":"code","metadata":{"id":"60y6Yy7zoJGg","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yxr-oTnaoJGh","colab_type":"code","outputId":"6329ad42-3bb1-44bf-d5d6-3212ab2dad87","executionInfo":{"status":"ok","timestamp":1572099830577,"user_tz":240,"elapsed":11538,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["setosa = feature_data[target_data==0]\n","versicolor = feature_data[target_data==1]\n","virginica = feature_data[target_data==2]\n","\n","plt.scatter(setosa[:,0], setosa[:,1], label=\"setosa\")\n","plt.scatter(versicolor[:,0], versicolor[:,1], label=\"versicolor\")\n","plt.scatter(virginica[:,0], virginica[:,1], label=\"virginica\")\n","\n","plt.legend()\n","plt.xlabel(\"sepal length (cm)\")\n","plt.ylabel(\"sepal width (cm)\")\n","plt.title(\"Visual EDA\");"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"CqiWXVGToJGi","colab_type":"text"},"source":["In the above step, we used boolean indexing to filter the feature data based on the target data class. This allowed us to create a scatter plot for each of the iris classes and distinguish them by color.\n","\n","*Observations*: We can see that the \"setosa\" class typically consists of medium-to-high sepal width with low-to-medium sepal length, while the other two classes have lower width and higher length. The \"virginica\" class appears to have the largest combination of the two. \n","\n","**YOUR TURN:** \n","* Which of the iris classes is seperable based on sepal characteristics? ___\"setoda class\" _____________\n","* Which of the iris classes is not? ____\"versicolor\" and \"virginica\"____________\n","* Can we (easily) visualize each of the samples w.r.t. all features on the same plot? Why/why not? _____(see below)___________"]},{"cell_type":"markdown","metadata":{"id":"sgEjwszdSLPB","colab_type":"text"},"source":["*   The \"setoda class\" is seperable based on sepal characteristics since most of the points of \"setosa\" clustered seperated from the rest two classes.\n","*   The \"versicolor\" and \"virginica\" are not seperable since they are clustered together.\n","*   No, it is hard to visualize each of the sample w.r.t. all features on the same plot since if all the features are included in the plot, there is going to be 4 axis (spepal width, sepal length, petal width and petal length) and it is very hard to display a 4 dimension plot on the screen (which has only 2 axis)."]},{"cell_type":"markdown","metadata":{"id":"6yar5YTAoJGj","colab_type":"text"},"source":["### Creating a Nearest Neighbors Classifier\n","\n","Now that we've explored the data a little bit, we're going to use scikit-learn to create a nearest neighbors classifier for the data. Effectively we'll be developing a model whose job it is to build a relationship over input feature data (sepal and petal characteristics) that predicts the iris sample class (e.g. \"setosa\"). This is an example of a *supervised learning* task; we have all the features and all the target classes.\n","\n","Model creation in scikit-learn follows a **data prep -> fit -> predict** process. The \"fit\" function is where the actual model is trained and parameter values are selected, while the \"predict\" function actually takes the trained model and applies it to the new samples.\n","\n","First, we load the nearest neighbor library from scikit-learn:"]},{"cell_type":"code","metadata":{"id":"_yFpq-h9oJGj","colab_type":"code","colab":{}},"source":["from sklearn import neighbors"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CPzTtk8roJGk","colab_type":"text"},"source":["Now, we're going to save our feature data into an array called 'X' and our target data into an array called 'y'. We don't *need* to do this, but it is traditional to think of the problem using this notation."]},{"cell_type":"code","metadata":{"id":"CZX6WgMjoJGk","colab_type":"code","colab":{}},"source":["X = feature_data\n","y = target_data"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sags3EJ4oJGm","colab_type":"text"},"source":["Next, we create our nearest neighbor classifier object:"]},{"cell_type":"code","metadata":{"id":"TDby6Z-6oJGm","colab_type":"code","colab":{}},"source":["knn = neighbors.KNeighborsClassifier(n_neighbors=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ZaVns1ooJGo","colab_type":"text"},"source":["And then we *fit* it to the data (i.e., train the classifier)."]},{"cell_type":"code","metadata":{"id":"F2uDIsP9oJGq","colab_type":"code","outputId":"270a0763-f45e-48a0-c91c-8258756d48c7","executionInfo":{"status":"ok","timestamp":1572099830853,"user_tz":240,"elapsed":11800,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["knn.fit(X,y)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n","                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n","                     weights='uniform')"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"m9qLzshxoJGr","colab_type":"text"},"source":["Now we have a model! If you're new to this, you've officially built your first machine learning model. If you use \"knn.predict(*[[feature array here]]*)\", you can use your trained model to predict the class of a new iris sample. \n","\n","**YOUR TURN:**\n","* What is the predicted class of a new iris sample with feature vector [3,4,5,2]? What is its name? ____\"virginica\"____________\n","* Do you think this model is overfit or underfit to the iris dataset? Why? ____overfit, (reasons below)____________\n","* How many neighbors does our model consider when classifying a new sample? _____1___________"]},{"cell_type":"code","metadata":{"id":"ThmDOzVFoJGr","colab_type":"code","outputId":"49bcd88c-12b3-443d-ebf4-61826f491b60","executionInfo":{"status":"ok","timestamp":1572099830853,"user_tz":240,"elapsed":11792,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["predictedClass = knn.predict(np.array([[3,4,5,2]]))\n","print(\"* The predicted class of a new iris sample with feature vector [3,4,5,2] is \\\"\", target_names[int(predictedClass[0])], \"\\\".\")\n","print(\"* This model is overfitting to the iris dataset since it is shown that 100% of sample fits the model, which means all the sample falls on the model. \\n  It is unlikely that a relatively large sample can fit on a model with no error. However, the methodology of the fitting model also explains that \\n  this is an overfit since the number of neighbours is 1 and the test sample is selected from the training sample. The model treat some of the noise as part of the feature of the data trend.\")\n","print(\"* There are \", knn.n_neighbors, \"neighbours that the model is considering when classifying a new sample\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["* The predicted class of a new iris sample with feature vector [3,4,5,2] is \" virginica \".\n","* This model is overfitting to the iris dataset since it is shown that 100% of sample fits the model, which means all the sample falls on the model. \n","  It is unlikely that a relatively large sample can fit on a model with no error. However, the methodology of the fitting model also explains that \n","  this is an overfit since the number of neighbours is 1 and the test sample is selected from the training sample. The model treat some of the noise as part of the feature of the data trend.\n","* There are  1 neighbours that the model is considering when classifying a new sample\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"grjsglM5oJGs","colab_type":"text"},"source":["As you may have noted in the previous cell, we've trained this classifier on our *entire dataset*. This typically isn't done in practice and results in overfitting to the data. Here's a bit of a tricky question:\n","\n","**YOUR TURN:**\n","* If we use our classifier to predict the classes of the iris samples that were used to train the model itself, what will our overall accuracy be? __100%______________\n","\n","We can validate our hypothesis fairly easily using either: i) the NumPy technique for calculating accuracy we used earlier in the lab, or ii) scikit-learn's in-house \"accuracy_score()\" function.\n","\n","Let's use our technique first:"]},{"cell_type":"code","metadata":{"id":"czS77Os8oJGt","colab_type":"code","outputId":"9c58086c-9294-4b72-8dea-4127f3754fab","executionInfo":{"status":"ok","timestamp":1572099830854,"user_tz":240,"elapsed":11787,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["accuracy = np.sum(target_data == knn.predict(feature_data)) / target_data.size\n","print (\"Accuracy: \", accuracy * 100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy:  100.0 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VlRFSBWIoJGu","colab_type":"text"},"source":["and then using scikit-learn's customized function:"]},{"cell_type":"code","metadata":{"id":"ae7QXH_EoJGu","colab_type":"code","outputId":"bc59cb00-7a05-4c1c-bc3f-220a116d9b0f","executionInfo":{"status":"ok","timestamp":1572099830855,"user_tz":240,"elapsed":11781,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import accuracy_score\n","accuracy = accuracy_score(target_data, knn.predict(feature_data))\n","print (\"Accuracy: \", accuracy * 100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy:  100.0 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ojZn8Ly8oJGw","colab_type":"text"},"source":["We see that our classifier has achieved 100% accuracy (and both calculation methods agree)!\n","\n","**DISCUSSION:** \n","* Why do you think the model was able to achieve such a \"great\" result? \n","* What does this really tell us? \n","* Do you expect the model to perform this well on new data?"]},{"cell_type":"markdown","metadata":{"id":"TYhrv5g3159P","colab_type":"text"},"source":["\n","**ANSWER:**\n","*   Because the data used for the prediction is from the original data used to train the classifier and based on the stratigy the classifier implimented. The classifier only consider one closest neighbor which is near the datum which needs to be classified. In this case, the neighbor will be exactaly the same as the candidate datum.\n","*   It tells us that it is inappropriate to include the sample which will be used for prediction to train the model, because it will cause overfitting.\n","*   No, because the classifier is overfitting and captures potential error and noise as part of the features of the predicted model.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"G5K78afZoJG4","colab_type":"text"},"source":["### Exercises (to be completed on your own)\n","\n","Let's take the tools we have learned in this lab and put them into practice on a new dataset.\n","\n","We're going to work with a dataset focused on diabetes. It contains a variety of health metrics for a number of patients, and then in a second object it shows whether or not that patient had diabetes. Download it using the cell below:"]},{"cell_type":"code","metadata":{"id":"SkFlVlNGoJG4","colab_type":"code","colab":{}},"source":["from sklearn.datasets import fetch_openml\n","\n","diabetes_data = fetch_openml(\n","    name='diabetes',\n","    cache=False\n",")\n","\n","df = pd.DataFrame(data=diabetes_data.data, columns=diabetes_data.feature_names)\n","\n","df['target'] = diabetes_data.target\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BLwmertOoJG5","colab_type":"text"},"source":["First off, take a look at the `data`, `target` and `feature_names` entires in the `diabetes_data` dictionary. They contain the information we'll be working with here. Then, create a Pandas DataFrame called `diabetes_df` containing the data and the targets, with the feature names as column headings. If you need help, refer [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) for more detail on how to achieve this.\n","\n","* What was the average age of participants? [1] _33.24___\n","* How many participants tested positive? How many tested negative? [1] __268 tested positive, 500 tested negative__"]},{"cell_type":"code","metadata":{"id":"oOgVWHG-oJG5","colab_type":"code","outputId":"2404e816-e60e-424d-8c27-82aca2a1f041","executionInfo":{"status":"ok","timestamp":1572099837490,"user_tz":240,"elapsed":18407,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["### YOUR CODE HERE\n","df.isnull().sum()\n","averageAge = df['age'].mean()\n","print(\"* The average age of the participants is \", '{:.2f}'.format(averageAge), \".\")\n","print(\"* There are\",sum(df['target'] == 'tested_positive'), \"participants tested positive and\",sum(df['target'] == 'tested_negative'),\"participants tested negative.\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["* The average age of the participants is  33.24 .\n","* There are 268 participants tested positive and 500 participants tested negative.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i7qnyte6oJG6","colab_type":"text"},"source":["The targets are currently a string representing whether or not the patient has diabetes. However, it's more useful for us if this column contains a 1 or a 0 depending on whether the patient has diabetes. Use the [Label Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) class from Scikit-Learn to convert the labels into integers."]},{"cell_type":"code","metadata":{"id":"rqDw_D2doJG7","colab_type":"code","outputId":"7c5c397c-3a2c-4780-9c52-431359967a46","executionInfo":{"status":"ok","timestamp":1572099837491,"user_tz":240,"elapsed":18401,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["from sklearn.preprocessing import LabelEncoder\n","### YOUR CODE HERE\n","le = sklearn.preprocessing.LabelEncoder()\n","le.fit(['tested_negative','tested_positive'])\n","df['target_in_digit'] = le.transform(df['target'])\n","\n","diabetes_feature_data = diabetes_data.data\n","diabetes_target_data = np.array(df['target_in_digit'])\n","\n","df"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preg</th>\n","      <th>plas</th>\n","      <th>pres</th>\n","      <th>skin</th>\n","      <th>insu</th>\n","      <th>mass</th>\n","      <th>pedi</th>\n","      <th>age</th>\n","      <th>target</th>\n","      <th>target_in_digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.0</td>\n","      <td>148.0</td>\n","      <td>72.0</td>\n","      <td>35.0</td>\n","      <td>0.0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>85.0</td>\n","      <td>66.0</td>\n","      <td>29.0</td>\n","      <td>0.0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8.0</td>\n","      <td>183.0</td>\n","      <td>64.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>89.0</td>\n","      <td>66.0</td>\n","      <td>23.0</td>\n","      <td>94.0</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>137.0</td>\n","      <td>40.0</td>\n","      <td>35.0</td>\n","      <td>168.0</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>10.0</td>\n","      <td>101.0</td>\n","      <td>76.0</td>\n","      <td>48.0</td>\n","      <td>180.0</td>\n","      <td>32.9</td>\n","      <td>0.171</td>\n","      <td>63.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>2.0</td>\n","      <td>122.0</td>\n","      <td>70.0</td>\n","      <td>27.0</td>\n","      <td>0.0</td>\n","      <td>36.8</td>\n","      <td>0.340</td>\n","      <td>27.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>5.0</td>\n","      <td>121.0</td>\n","      <td>72.0</td>\n","      <td>23.0</td>\n","      <td>112.0</td>\n","      <td>26.2</td>\n","      <td>0.245</td>\n","      <td>30.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>1.0</td>\n","      <td>126.0</td>\n","      <td>60.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>30.1</td>\n","      <td>0.349</td>\n","      <td>47.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>1.0</td>\n","      <td>93.0</td>\n","      <td>70.0</td>\n","      <td>31.0</td>\n","      <td>0.0</td>\n","      <td>30.4</td>\n","      <td>0.315</td>\n","      <td>23.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows × 10 columns</p>\n","</div>"],"text/plain":["     preg   plas  pres  skin  ...   pedi   age           target  target_in_digit\n","0     6.0  148.0  72.0  35.0  ...  0.627  50.0  tested_positive                1\n","1     1.0   85.0  66.0  29.0  ...  0.351  31.0  tested_negative                0\n","2     8.0  183.0  64.0   0.0  ...  0.672  32.0  tested_positive                1\n","3     1.0   89.0  66.0  23.0  ...  0.167  21.0  tested_negative                0\n","4     0.0  137.0  40.0  35.0  ...  2.288  33.0  tested_positive                1\n","..    ...    ...   ...   ...  ...    ...   ...              ...              ...\n","763  10.0  101.0  76.0  48.0  ...  0.171  63.0  tested_negative                0\n","764   2.0  122.0  70.0  27.0  ...  0.340  27.0  tested_negative                0\n","765   5.0  121.0  72.0  23.0  ...  0.245  30.0  tested_negative                0\n","766   1.0  126.0  60.0   0.0  ...  0.349  47.0  tested_positive                1\n","767   1.0   93.0  70.0  31.0  ...  0.315  23.0  tested_negative                0\n","\n","[768 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"kANitNmToJG9","colab_type":"text"},"source":["Now we are going to create a classifier to predict whether a patient has diabetes based on their vitals. \n","\n","Using `cross_val_score`, report mean cross validation accuracy on a KNN classifier with K=3 and 10 folds. Remember that the `target` column holds our labels.\n","\n","* What accuracy did the model achieve?[1] _(see code out put print below)_70.31%__\n","* Find a value for K that performs better than this. What value for K did you use? What was the performance? [2] __(see code out put print below)__K=17, 75.53%"]},{"cell_type":"code","metadata":{"id":"oIDm_Cn5oJG9","colab_type":"code","outputId":"ea54d2ba-fe44-4a38-eab7-e8d0c9b1bc0f","executionInfo":{"status":"ok","timestamp":1572099840206,"user_tz":240,"elapsed":21101,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["### YOUR CODE HERE\n","from sklearn.model_selection import cross_val_score\n","\n","knn.n_neighbors = 3\n","\n","scores = cross_val_score(knn, diabetes_feature_data, diabetes_target_data, cv=10, scoring='accuracy')\n","\n","meanScore = scores.mean()\n","\n","print(\"* The accuracy that the model achieve is\", meanScore,\".\")\n","\n","#now try to find a value thats better, prepare a loop to seek for best K\n","\n","scoreRecord = []\n","#Record each accuracy value for a range of K from 1 to 50\n","\n","print(\"===>Now try to find K with best cross_val_score\")\n","\n","for k in range(1,50,1):\n","  knn.n_neighbors = k\n","  scoreRecord.append(cross_val_score(knn, diabetes_feature_data, diabetes_target_data, cv=10, scoring='accuracy').mean())\n","\n","  \n","for i in range(len(scoreRecord)):\n","  print(\"K=\", i+1,\",Cross val score=\",scoreRecord[i])\n","print(\"===>K with value of\",scoreRecord.index(max(scoreRecord))+1, \"has best cross_val_score of \",max(scoreRecord))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["* The accuracy that the model achieve is 0.7030587833219413 .\n","===>Now try to find K with best cross_val_score\n","K= 1 ,Cross val score= 0.6796650717703349\n","K= 2 ,Cross val score= 0.7122351332877648\n","K= 3 ,Cross val score= 0.7030587833219413\n","K= 4 ,Cross val score= 0.7187115516062884\n","K= 5 ,Cross val score= 0.7213773069036227\n","K= 6 ,Cross val score= 0.7357142857142858\n","K= 7 ,Cross val score= 0.7396274777853726\n","K= 8 ,Cross val score= 0.7383116883116883\n","K= 9 ,Cross val score= 0.7383458646616542\n","K= 10 ,Cross val score= 0.7434723171565277\n","K= 11 ,Cross val score= 0.7369446343130555\n","K= 12 ,Cross val score= 0.7473684210526316\n","K= 13 ,Cross val score= 0.7422077922077922\n","K= 14 ,Cross val score= 0.7539131920710869\n","K= 15 ,Cross val score= 0.7448051948051948\n","K= 16 ,Cross val score= 0.7526144907723855\n","K= 17 ,Cross val score= 0.7552973342447027\n","K= 18 ,Cross val score= 0.7552802460697198\n","K= 19 ,Cross val score= 0.7474709501025291\n","K= 20 ,Cross val score= 0.7461893369788107\n","K= 21 ,Cross val score= 0.7500683526999316\n","K= 22 ,Cross val score= 0.7501196172248804\n","K= 23 ,Cross val score= 0.7475222146274778\n","K= 24 ,Cross val score= 0.7435919343814081\n","K= 25 ,Cross val score= 0.7462064251537937\n","K= 26 ,Cross val score= 0.7331681476418319\n","K= 27 ,Cross val score= 0.7370813397129188\n","K= 28 ,Cross val score= 0.7305365686944635\n","K= 29 ,Cross val score= 0.7318523581681476\n","K= 30 ,Cross val score= 0.7253588516746412\n","K= 31 ,Cross val score= 0.7344497607655502\n","K= 32 ,Cross val score= 0.7318523581681476\n","K= 33 ,Cross val score= 0.7370642515379358\n","K= 34 ,Cross val score= 0.7357484620642516\n","K= 35 ,Cross val score= 0.7422419685577581\n","K= 36 ,Cross val score= 0.7370300751879699\n","K= 37 ,Cross val score= 0.7357313738892687\n","K= 38 ,Cross val score= 0.7422590567327411\n","K= 39 ,Cross val score= 0.7383800410116199\n","K= 40 ,Cross val score= 0.7383971291866029\n","K= 41 ,Cross val score= 0.7383629528366371\n","K= 42 ,Cross val score= 0.7293233082706767\n","K= 43 ,Cross val score= 0.7319036226930964\n","K= 44 ,Cross val score= 0.7280075187969925\n","K= 45 ,Cross val score= 0.7280246069719755\n","K= 46 ,Cross val score= 0.7228127136021874\n","K= 47 ,Cross val score= 0.7319207108680793\n","K= 48 ,Cross val score= 0.7267259056732742\n","K= 49 ,Cross val score= 0.7319207108680793\n","===>K with value of 17 has best cross_val_score of  0.7552973342447027\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mYPM-3wHoJG-","colab_type":"text"},"source":["Take a look at the `skin` feature.\n","\n","* According to the dataset description in `diabetes_data['DESCR']`, what does this feature represent? [1] __'Triceps skin fold thickness (mm)'__\n","* Are there any unusual entries in this column? If so, why? [2] __There are several rows with 'skin' value of 0.0 however, 0.0 is pretty far away from other usual values, which suggests that rows with 'skin' of value 0.0 might have missing data for 'skin'__\n","\n","Use the `SimpleImputer` class from scikit-learn to impute missing values for the `skin` and `insu` columns. Overwrite the existing `skin` and `insu` columns with these new values."]},{"cell_type":"code","metadata":{"id":"90gCGSVHoJG-","colab_type":"code","outputId":"8166d4ff-857e-4bfc-e7ed-1c6067e691d7","executionInfo":{"status":"ok","timestamp":1572099840207,"user_tz":240,"elapsed":21094,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["### YOUR CODE HERE\n","print(diabetes_data['DESCR'])\n","\n","print(\"According to 'DESCR', feature 'skin' represent 'Triceps skin fold thickness (mm)''\")\n","\n","print(df['skin'])\n","\n","\n","imp_mean = SimpleImputer(missing_values=0.0, strategy='mean')\n","\n","imp_mean.fit(df[['skin', 'insu']])\n","\n","df[['skin', 'insu']] = imp_mean.transform(df[['skin', 'insu']])\n","\n","df[['skin', 'insu']] = df[['skin', 'insu']]\n","\n","df"],"execution_count":0,"outputs":[{"output_type":"stream","text":["**Author**: [Vincent Sigillito](vgs@aplcen.apl.jhu.edu)  \n","\n","**Source**: [Obtained from UCI](https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes) \n","\n","**Please cite**: [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)  \n","\n","1. Title: Pima Indians Diabetes Database\n"," \n"," 2. Sources:\n","    (a) Original owners: National Institute of Diabetes and Digestive and\n","                         Kidney Diseases\n","    (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)\n","                           Research Center, RMI Group Leader\n","                           Applied Physics Laboratory\n","                           The Johns Hopkins University\n","                           Johns Hopkins Road\n","                           Laurel, MD 20707\n","                           (301) 953-6231\n","    (c) Date received: 9 May 1990\n"," \n"," 3. Past Usage:\n","     1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., &\n","        Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast\n","        the onset of diabetes mellitus.  In {it Proceedings of the Symposium\n","        on Computer Applications and Medical Care} (pp. 261--265).  IEEE\n","        Computer Society Press.\n"," \n","        The diagnostic, binary-valued variable investigated is whether the\n","        patient shows signs of diabetes according to World Health Organization\n","        criteria (i.e., if the 2 hour post-load plasma glucose was at least \n","        200 mg/dl at any survey  examination or if found during routine medical\n","        care).   The population lives near Phoenix, Arizona, USA.\n"," \n","        Results: Their ADAP algorithm makes a real-valued prediction between\n","        0 and 1.  This was transformed into a binary decision using a cutoff of \n","        0.448.  Using 576 training instances, the sensitivity and specificity\n","        of their algorithm was 76% on the remaining 192 instances.\n"," \n"," 4. Relevant Information:\n","       Several constraints were placed on the selection of these instances from\n","       a larger database.  In particular, all patients here are females at\n","       least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning\n","       routine that generates and executes digital analogs of perceptron-like\n","       devices.  It is a unique algorithm; see the paper for details.\n"," \n"," 5. Number of Instances: 768\n"," \n"," 6. Number of Attributes: 8 plus class \n"," \n"," 7. For Each Attribute: (all numeric-valued)\n","    1. Number of times pregnant\n","    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n","    3. Diastolic blood pressure (mm Hg)\n","    4. Triceps skin fold thickness (mm)\n","    5. 2-Hour serum insulin (mu U/ml)\n","    6. Body mass index (weight in kg/(height in m)^2)\n","    7. Diabetes pedigree function\n","    8. Age (years)\n","    9. Class variable (0 or 1)\n"," \n"," 8. Missing Attribute Values: None\n"," \n"," 9. Class Distribution: (class value 1 is interpreted as \"tested positive for\n","    diabetes\")\n"," \n","    Class Value  Number of instances\n","    0            500\n","    1            268\n"," \n"," 10. Brief statistical analysis:\n"," \n","     Attribute number:    Mean:   Standard Deviation:\n","     1.                     3.8     3.4\n","     2.                   120.9    32.0\n","     3.                    69.1    19.4\n","     4.                    20.5    16.0\n","     5.                    79.8   115.2\n","     6.                    32.0     7.9\n","     7.                     0.5     0.3\n","     8.                    33.2    11.8\n"," \n"," \n","\n","\n","\n","\n"," Relabeled values in attribute 'class'\n","    From: 0                       To: tested_negative     \n","    From: 1                       To: tested_positive\n","\n","Downloaded from openml.org.\n","According to 'DESCR', feature 'skin' represent 'Triceps skin fold thickness (mm)''\n","0      35.0\n","1      29.0\n","2       0.0\n","3      23.0\n","4      35.0\n","       ... \n","763    48.0\n","764    27.0\n","765    23.0\n","766     0.0\n","767    31.0\n","Name: skin, Length: 768, dtype: float64\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>preg</th>\n","      <th>plas</th>\n","      <th>pres</th>\n","      <th>skin</th>\n","      <th>insu</th>\n","      <th>mass</th>\n","      <th>pedi</th>\n","      <th>age</th>\n","      <th>target</th>\n","      <th>target_in_digit</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.0</td>\n","      <td>148.0</td>\n","      <td>72.0</td>\n","      <td>35.00000</td>\n","      <td>155.548223</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>85.0</td>\n","      <td>66.0</td>\n","      <td>29.00000</td>\n","      <td>155.548223</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8.0</td>\n","      <td>183.0</td>\n","      <td>64.0</td>\n","      <td>29.15342</td>\n","      <td>155.548223</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>89.0</td>\n","      <td>66.0</td>\n","      <td>23.00000</td>\n","      <td>94.000000</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>137.0</td>\n","      <td>40.0</td>\n","      <td>35.00000</td>\n","      <td>168.000000</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>10.0</td>\n","      <td>101.0</td>\n","      <td>76.0</td>\n","      <td>48.00000</td>\n","      <td>180.000000</td>\n","      <td>32.9</td>\n","      <td>0.171</td>\n","      <td>63.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>2.0</td>\n","      <td>122.0</td>\n","      <td>70.0</td>\n","      <td>27.00000</td>\n","      <td>155.548223</td>\n","      <td>36.8</td>\n","      <td>0.340</td>\n","      <td>27.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>5.0</td>\n","      <td>121.0</td>\n","      <td>72.0</td>\n","      <td>23.00000</td>\n","      <td>112.000000</td>\n","      <td>26.2</td>\n","      <td>0.245</td>\n","      <td>30.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>1.0</td>\n","      <td>126.0</td>\n","      <td>60.0</td>\n","      <td>29.15342</td>\n","      <td>155.548223</td>\n","      <td>30.1</td>\n","      <td>0.349</td>\n","      <td>47.0</td>\n","      <td>tested_positive</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>1.0</td>\n","      <td>93.0</td>\n","      <td>70.0</td>\n","      <td>31.00000</td>\n","      <td>155.548223</td>\n","      <td>30.4</td>\n","      <td>0.315</td>\n","      <td>23.0</td>\n","      <td>tested_negative</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows × 10 columns</p>\n","</div>"],"text/plain":["     preg   plas  pres      skin  ...   pedi   age           target  target_in_digit\n","0     6.0  148.0  72.0  35.00000  ...  0.627  50.0  tested_positive                1\n","1     1.0   85.0  66.0  29.00000  ...  0.351  31.0  tested_negative                0\n","2     8.0  183.0  64.0  29.15342  ...  0.672  32.0  tested_positive                1\n","3     1.0   89.0  66.0  23.00000  ...  0.167  21.0  tested_negative                0\n","4     0.0  137.0  40.0  35.00000  ...  2.288  33.0  tested_positive                1\n","..    ...    ...   ...       ...  ...    ...   ...              ...              ...\n","763  10.0  101.0  76.0  48.00000  ...  0.171  63.0  tested_negative                0\n","764   2.0  122.0  70.0  27.00000  ...  0.340  27.0  tested_negative                0\n","765   5.0  121.0  72.0  23.00000  ...  0.245  30.0  tested_negative                0\n","766   1.0  126.0  60.0  29.15342  ...  0.349  47.0  tested_positive                1\n","767   1.0   93.0  70.0  31.00000  ...  0.315  23.0  tested_negative                0\n","\n","[768 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"M0uktoPhoJG_","colab_type":"text"},"source":["Re-split the data and fit a new classifier.\n","\n","* Is performance better or worse with imputed values? Why might this be? [2] __The data set with imputed values gives a better cross evaluation score of 75.79% with K=18. Because the new data set is imputed and the error data (0 values) are replaced with better values (mean values). "]},{"cell_type":"code","metadata":{"id":"9impREmUoJHA","colab_type":"code","outputId":"e3fc1944-681c-4715-c9aa-db338ad19863","executionInfo":{"status":"ok","timestamp":1572099844141,"user_tz":240,"elapsed":25018,"user":{"displayName":"Yixiao Hong","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCqRbcleOBsu7BY5rkdhOB8_ETaQLqEu_bY03Uu=s64","userId":"10210502346910599728"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["### YOUR CODE HERE\n","diabetes_feature_data = df.drop(columns=['target','target_in_digit'])\n","diabetes_target_data = np.array(df['target_in_digit'])\n","knn.n_neighbors = 3\n","scores = cross_val_score(knn, diabetes_feature_data, diabetes_target_data, cv=10, scoring='accuracy')\n","\n","meanScore = scores.mean()\n","\n","print(\"* The accuracy that the model achieve is\", meanScore,\".\")\n","\n","#now try to find a value thats better, prepare a loop to seek for best K\n","\n","scoreRecord = []\n","#Record each accuracy value for a range of K from 1 to 50\n","\n","print(\"===>Now try to find K with best cross_val_score\")\n","\n","for k in range(1,50,1):\n","  knn.n_neighbors = k\n","  scoreRecord.append(cross_val_score(knn, diabetes_feature_data, diabetes_target_data, cv=10, scoring='accuracy').mean())\n","\n","  \n","for i in range(len(scoreRecord)):\n","  print(\"K=\", i+1,\",Cross val score=\",scoreRecord[i])\n","print(\"===>K with value of\",scoreRecord.index(max(scoreRecord))+1, \"has best cross_val_score of \",max(scoreRecord))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["* The accuracy that the model achieve is 0.7057416267942583 .\n","===>Now try to find K with best cross_val_score\n","K= 1 ,Cross val score= 0.6940191387559808\n","K= 2 ,Cross val score= 0.7240088858509911\n","K= 3 ,Cross val score= 0.7057416267942583\n","K= 4 ,Cross val score= 0.7317840054682159\n","K= 5 ,Cross val score= 0.7213431305536568\n","K= 6 ,Cross val score= 0.740909090909091\n","K= 7 ,Cross val score= 0.7344668489405332\n","K= 8 ,Cross val score= 0.7474538619275461\n","K= 9 ,Cross val score= 0.7410116199589885\n","K= 10 ,Cross val score= 0.7526657552973343\n","K= 11 ,Cross val score= 0.742276144907724\n","K= 12 ,Cross val score= 0.7513841421736159\n","K= 13 ,Cross val score= 0.7462064251537937\n","K= 14 ,Cross val score= 0.756596035543404\n","K= 15 ,Cross val score= 0.7488038277511964\n","K= 16 ,Cross val score= 0.7566473000683527\n","K= 17 ,Cross val score= 0.750170881749829\n","K= 18 ,Cross val score= 0.7579460013670541\n","K= 19 ,Cross val score= 0.7566473000683527\n","K= 20 ,Cross val score= 0.7539986329460013\n","K= 21 ,Cross val score= 0.747488038277512\n","K= 22 ,Cross val score= 0.7527170198222829\n","K= 23 ,Cross val score= 0.7410287081339713\n","K= 24 ,Cross val score= 0.7501196172248804\n","K= 25 ,Cross val score= 0.743626110731374\n","K= 26 ,Cross val score= 0.7501025290498975\n","K= 27 ,Cross val score= 0.748855092276145\n","K= 28 ,Cross val score= 0.7475905673274095\n","K= 29 ,Cross val score= 0.7515037593984963\n","K= 30 ,Cross val score= 0.7475734791524266\n","K= 31 ,Cross val score= 0.7527682843472316\n","K= 32 ,Cross val score= 0.7475222146274778\n","K= 33 ,Cross val score= 0.7462406015037594\n","K= 34 ,Cross val score= 0.7501196172248804\n","K= 35 ,Cross val score= 0.7436431989063568\n","K= 36 ,Cross val score= 0.7462406015037594\n","K= 37 ,Cross val score= 0.7501367053998633\n","K= 38 ,Cross val score= 0.7475051264524949\n","K= 39 ,Cross val score= 0.7449419002050581\n","K= 40 ,Cross val score= 0.7475393028024608\n","K= 41 ,Cross val score= 0.7462064251537937\n","K= 42 ,Cross val score= 0.7488721804511279\n","K= 43 ,Cross val score= 0.7501708817498292\n","K= 44 ,Cross val score= 0.7475734791524266\n","K= 45 ,Cross val score= 0.7436773752563226\n","K= 46 ,Cross val score= 0.7410628844839371\n","K= 47 ,Cross val score= 0.7423786739576214\n","K= 48 ,Cross val score= 0.7397641831852357\n","K= 49 ,Cross val score= 0.7423786739576214\n","===>K with value of 18 has best cross_val_score of  0.7579460013670541\n"],"name":"stdout"}]}]}